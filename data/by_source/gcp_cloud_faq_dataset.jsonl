{"source":"gcp","filename":"ai_platform_data_labeling_docs_faq","question":"can you provide any information about the security and protection of my\n    data?","answer":"all data used in ai platform data labeling service and stored in google cloud is\n    encrypted by default"}
{"source":"gcp","filename":"ai_platform_data_labeling_docs_faq","question":"can i label healthcare data?","answer":"yes, ai platform data labeling service is\n    hipaa compliant and can be used to\n    label healthcare data"}
{"source":"gcp","filename":"ai_platform_data_labeling_docs_faq","question":"what quality control methods can i use to ensure the labeling quality?","answer":"you can request multiple human labelers to annotate each piece of your\n      data"}
{"source":"gcp","filename":"ai_platform_data_labeling_docs_faq","question":"what is the difference between a \"task\" and an \"operation\"?","answer":"a task is an action you perform using data labeling service, such\n    as importing data, exporting data, or requesting labeling"}
{"source":"gcp","filename":"ai_platform_data_labeling_docs_faq","question":"how do i know when an (import, export, or labeling) operation is done?","answer":"when you use the data labeling service api to request import, export, or\n    labeling, the response includes the name of the operation that will be completing\n    the requested task"}
{"source":"gcp","filename":"ai_platform_data_labeling_docs_faq","question":"how do i get the id of the annotated dataset after requesting labeling?","answer":"listannotateddatasets\n    returns the names of your annotated datasets"}
{"source":"gcp","filename":"ai_platform_data_labeling_docs_faq","question":"what does it mean when i get an httperror 404 with the message \"the requested\n    resource accesses are not available. this request is rejected because of resource conflict.\"?","answer":"it means that another running operation is using the resource"}
{"source":"gcp","filename":"ai_platform_data_labeling_docs_faq","question":"why can't i delete my dataset\/instruction\/labeling task?","answer":"there is probably a resource conflict because a running operation is using\n    the resource"}
{"source":"gcp","filename":"ai_platform_data_labeling_docs_faq","question":"do i have to manually type in all my labels one at a time to create a label set?","answer":"yes, if you are using the ai platform data labeling service ui"}
{"source":"gcp","filename":"ai_platform_data_labeling_docs_faq","question":"why does my image bounding box data labeling request returns within a few\n    minutes with no annotations?","answer":"most likely your image format is not supported"}
{"source":"gcp","filename":"ai_platform_data_labeling_docs_faq","question":"why is the progress percentage still at zero a while after i submitted my\n    labeling task?","answer":"two possible reasons (you can reach out to\n      cloudml-data-customer@google"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"what is cloud sql?","answer":"cloud sql is a service that delivers fully managed sql databases in the cloud"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"what are the benefits of using cloud sql?","answer":"cloud sql lets you hand\noff to google the mundane, but necessary and often time consuming tasks \u2014 like applying patches and\nupdates, managing backups and configuring replications \u2014 so you can put your focus on building great\napplications"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"does cloud sql support all database features?","answer":"cloud sql supports most of the common features of sql server"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"are there any size or qps limits?","answer":"there are no queries per second (qps) limits for cloud sql instances"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"how can i be notified when there are any changes to cloud sql?","answer":"you can sign up for the google-cloud-sql-announce\n  forum where we post announcements and news about cloud sql"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"how do i report a bug, request a feature, or ask a question?","answer":"you can report bugs and request a feature on our\n  google-cloud-sql-discuss\n  group"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"why does my new instance with no data show disk space used?","answer":"cloud sql and the database both use some space for system files and metadata when\n  your instance is created"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"what is a zone?","answer":"a zone is an independent entity in a specific geographical location where you can run your\nresources"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"what are the limits on storage?","answer":"for information on storage limits, see\n    \n  quotas and limits"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"how is my data replicated?","answer":"sql server instances provide a\n    high availability configuration and\n    read replicas"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"what kind of read replicas can i create?","answer":"for more information about read replicas, including use cases for each\n  type, see replication options"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"how does cloud sql failover work?","answer":"for information about failover, see\n    overview of the high availability\n      configuration"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"is my data encrypted?","answer":"cloud sql customer data is encrypted when stored in database tables, temporary files,\n  and backups"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"how is encryption managed for data in transit?","answer":"google encrypts and authenticates all data in transit at one or more network layers when data\n    moves outside physical boundaries not controlled by google or on behalf of google"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"does cloud sql for sql server integrate with managed service for\n      microsoft active directory?","answer":"yes, authentication, authorization, and more are available; as a starting point, see the\noverview"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"how do i recover an instance?","answer":"to restore to a backup you can use the google cloud console\n    or the gcloud command-line tool"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"how much do backups cost?","answer":"for more information about instance storage pricing and instance rates, see\n  pricing"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"can i access automated backups older than seven days?","answer":"automated backups occur every day and by default are retained for seven days"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"how long are instances shut down during restart?","answer":"when instances are restarted, the majority of them are shut down for one to two minutes"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"can i make my database larger or smaller?","answer":"you can increase the amount of storage available to your instance at any time without incurring\n  downtime"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"can i upgrade and downgrade vcpus?","answer":"yes, you can change the number of vcpus that you use on your instance"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"do i need to use the google cloud console to manage cloud sql?","answer":"no, all management tasks that can be done using the console can also be done programmatically\n  using the cloud sql admin api, or scripted using the\n  gcloud command-line tool"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"how can i reclaim the space used by temporary files?","answer":"temporary files can grow when sql queries create many\ntemporary tables"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"can i import or export a specific database?","answer":"yes, you can import or export a specific database or all databases on an instance"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"can i import or export a csv file?","answer":"csv is not currently supported in cloud sql for sql server"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"do i need a cloud storage account to import or export data to an\n  instance?","answer":"cloud sql supports importing and exporting databases"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"if i delete my instance, can i reuse the instance name?","answer":"yes, but not right away"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"why can't i find the sample query plan in insights?","answer":"we only have sample queries for getting the query plan, because of the performance impact it\n      can have on the query"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"how can i try out cloud sql?","answer":"the smallest instance is the db-f1-micro"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"how many instances can i create in a project?","answer":"for information about the instance limit, see \n  quotas and limits"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"what size database instance do i need? how much ram?","answer":"in general, you can increase the performance of your database by choosing a\n    larger instance with more ram and cpu"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"how is use of my instance calculated?","answer":"you are charged per minute for the time that your instance is on"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"how is storage calculated?","answer":"storage is calculated based on the amount of storage you have\n    provisioned for your instance"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"how can i see how much i will be charged?","answer":"the billing tab of the google cloud console\n    shows you the charges your instances have incurred since the last bill was issued"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"what happens when my instance reaches the allowed size?","answer":"if your instance reaches the provisioned storage size,\n    and you do not have automatic storage increase enabled or it has reached its configured limit,\n    future writes to the database are disallowed until you increase the storage size"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"why is my instance suspended?","answer":"this is probably due to an issue with your google cloud account"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"why was my instance deleted?","answer":"instances that are suspended for 90 days are deleted"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"how can i cancel my cloud sql account?","answer":"you can deactivate cloud sql for a project by visiting the\ngoogle cloud console, selecting the project,\n  selecting the api service to open the api dashboard"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"how do i disable billing?","answer":"you can disable billing by clicking disable billing\n  in the google cloud console billing & settings pane for a project"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"can i connect from app engine to a sql server instance?","answer":"you can connect from an app engine application to a sql server instance, depending on\n    the environment and language you are using"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"can my app engine application in the us access my cloud sql instance in\n  the eu (and the other way around)?","answer":"if you are connecting to a cloud sql instance, your app engine application does not\n    need to be in the same region"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"which google cloud database service is right for me?","answer":"this depends on the requirements of your application"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"do i need to install a local database server to use the app engine development server?","answer":"no, you can configure app engine to use either cloud sql or a locally installed\n  database server when running on the development server"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"what languages can i use to access my instance?","answer":"app engine standard environment supports several languages that you can use to connect to your\ninstances"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"can i use django with cloud sql?","answer":"yes, cloud sql is compatible with django"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"which placeholders can i use in my python query string?","answer":"python users can only use the %s format code in parameter substitution"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"how do i manage connections?","answer":"managing your database connections effectively is an important aspect of database application\n  development, including using connection pooling and exponential backoff"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"what does a sqlexception with message of \"invalid connection id\" mean?","answer":"it means that the connection is no longer open on the server and is discarded by the\n  client"}
{"source":"gcp","filename":"sql_docs_sqlserver_faq","question":"can i access my cloud sql instance programmatically outside of app engine?","answer":"yes, you can access cloud sql instances programmatically from external applications by using\n  any supported language"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"do you have client libraries for the retail api, or more\nsample code?","answer":"yes, you can see the client libraries guide for recommendations ai\nhere for setup and reference information for each library"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"are all the recommendation models personalized?","answer":"the \"recommended for you\" and \"others you may like\" models make personalized recommendations when\nprovided with user history"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"will i receive personalized recommendations immediately, or will i need to\nwait for these to improve over time?","answer":"recommendations improve as you collect more user history"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"are you using google user demographic data in your models?","answer":"the models only use the catalog and user event data that you provide"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"can i make recommendations based on the event history of a group of users,\nrather than a single user's history?","answer":"currently, recommendations are based on a single visitor id or user id"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"i noticed that you can submit image urls for products. do the models take\ninto consideration the product images?","answer":"not at this time, these fields are provided so that you can retrieve this\nmetadata along with the returned recommendation results, in order to aid in\nrendering recommendation results"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"my company isn't a retail ecommerce website. can i still use\nrecommendations ai for predicting x,y,z?","answer":"we've had customers use recommendations ai for content recommendations,\nvideo streaming and gaming, and other use cases"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"can i place recommendations on any page of my site?","answer":"yes, but the models are each designed for specific use cases and may work best\non certain pages"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"can i use recommendations ai for recommendations in email newsletters?","answer":"yes, this can be done by making a call to the api with a visitor id or user id,\nthen incorporating the results into an email template"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"can i use recommendations ai for other non-web use cases (mobile apps,\nkiosks)?","answer":"yes, you can set up an endpoint (eg"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"i don't have 3+ months of event data. can i still use recommendations ai?\ncan i add more data at a later point?","answer":"if you can record sufficient traffic for real-time events, recent data can be\nused for training"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"can i recommend categories along with products?","answer":"recommendations ai currently returns product recommendations only, but you\ncan get the categories for each product returned as part of the results"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"can i deploy recommendations ai on a website without modifying my existing\nserver-side code?","answer":"this is possible, but you still need an endpoint to handle the ajax request\nbecause the retail predict api is authenticated and uses a\npost request"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"do you have integrations for uploading data from sql databases or other\nsystems, such as bigquery?","answer":"yes, for events, there is sample code that reads from\nbigquery"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"why aren't my credentials working when using the retail api\nthrough cloud shell?","answer":"check that you've completed the authentication setup steps for\nrecommendations ai"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"i think feature x,y,z would be great. can you add this to\nrecommendations ai?","answer":"we'd love to hear from you"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"can i still use the old api?","answer":"recommendations ai has migrated from the recommendations engine api to the\nretail api"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"how does recommendations ai handle cold starts for new products?","answer":"for products that do not have any purchase history, we make recommendations\nbased on similar products"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"can i use my merchant center catalog for recommendations?","answer":"yes, you can export a merchant center catalog to\nbigquery using the merchant center data transfer\nservice"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"how else can i import my catalog?","answer":"how can i keep my catalog updated?  how often does the catalog need to be\nupdated?"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"how can i keep my catalog updated?  how often does the catalog need to be\nupdated?","answer":"see keeping your catalog up to date"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"are there minimum and maximum catalog sizes?","answer":"there is no minimum, but very small catalog sizes (< 100 items) may not see much\nbenefit from recommendations due to there being very few different products to\nrecommend"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"my company operates websites in multiple countries. should i use one catalog\nfor all of my data?","answer":"it is usually best to have just one catalog with all items"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"does recommendations ai support multiple currencies per catalog?","answer":"no, recommendations ai supports one currency type per catalog"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"i have multiple websites with a shared catalog or similar items. can\nrecommendations ai provide cross-site recommendations?","answer":"we typically recommend using a single catalog like this only if there is\nsignificant overlap between the sites; they should share many or all of the same\nproducts"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"does including more metadata improve the model? does the model consider fields\nx,y,z?","answer":"see required catalog item information for required fields"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"which attributes of a catalog item are used as inputs of model training?","answer":"a combination of both user behavior and product attributes is used"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"what languages are supported for my products?","answer":"the retail api supports most languages"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"my catalog has primary\/variant or parent\/child skus. are these supported?","answer":"yes, this would be similar to the item_group_id in\nmerchant center"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"can i integrate with google analytics 360?","answer":"you can use historical data from google analytics 360 (ga360)"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"how do i feed events into recommendations ai?","answer":"users typically import historical events using cloud storage or api import,\nthen stream real-time events using the javascript pixel or tag manager\ntag on the live site, or via the write method on the backend"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"what if i can't send all of the user event types listed as required for a\nmodel? what are the minimum event types needed for each model?","answer":"each model and optimization objective has slightly different requirements"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"i have add-to-cart and purchase-complete events that don't have a value for\nrevenue or quantity. what should i submit?","answer":"if you don't have a value for quantity, you can pass a default value of 1\nwithout affecting model results"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"my data only covered limited types of events. can i still use\nrecommendations ai?","answer":"see user event data requirements for the minimum data requirements\nof each model type"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"is there a limit to the number of predictions i can return?","answer":"by default, a prediction request returns 20 items in the response"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"am i able to view the reasons why a model made a specific product\nrecommendation?","answer":"not currently"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"can i download and cache prediction results?","answer":"since prediction results improve in real-time in response to user activity on\nyour site, we don't recommend using cached predictions"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"i need to rerank the returned recommendations based on a business rule. is\nthis supported?","answer":"yes, but while you can re-rank the returned recommendations based on your\nbusiness rules, be aware that re-ordering or filtering recommended results can\nreduce the overall effectiveness of the model at achieving the optimization goal\nthat you chose"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"are there restrictions on the number of filter tags that i can create and\nuse?","answer":"there are no hard limits on the number of unique tags that you can create or\nuse"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"how long does it take to train a model?","answer":"initial model training and tuning takes 2-5 days to complete"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"can i use models i created in an existing project in a new project?","answer":"no, you need to create and retrain the models in the new project"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"i want to use a model for my category pages. can i do that?","answer":"yes, \"recommended for you\" is useful on category pages"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"can i disable personalization for my models?","answer":"by default, prediction results are personalized by user for the\n\"others you may like\" and \"recommended for you\" recommendation model types"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"how can i tell if there are errors with my catalog or user events?","answer":"most api calls for catalog item updates or user events return an error if there\nis a problem with syntax or the request can't be processed for some reason"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"why do my recommendation placements show as inactive? how do i activate\nthem?","answer":"in order to use recommendation placements, you first need to submit\ncatalog and user event data to train the corresponding\nmodel"}
{"source":"gcp","filename":"retail_recommendations_ai_docs_faq","question":"in what currency does cloud console report revenue metrics?","answer":"recommendations ai cloud console reports metrics in the currency used in\nyour uploaded data"}
{"source":"gcp","filename":"appengine_docs_standard_java_java8_runtime_faq","question":"can i use kotlin with the java 8 runtime?","answer":"yes, check out our kotlin samples in the github repository"}
{"source":"gcp","filename":"appengine_docs_standard_java_java8_runtime_faq","question":"can i use intellij idea community edition with app engine?","answer":"yes, using the built-in maven integration"}
{"source":"gcp","filename":"appengine_docs_standard_java_java8_runtime_faq","question":"does app engine cloud endpoints v1.0 work in the java 8 runtime?","answer":"no, you must\nmigrate to cloud endpoints frameworks version 2"}
{"source":"gcp","filename":"appengine_docs_standard_java_java8_runtime_faq","question":"why do i get java.lang.noclassdeffounderror for repackaged classes?","answer":"repackaged internal classes, such as\ncom\/google\/appengine\/repackaged\/com\/google\/common\/collect\/immutablelist,\nare not available anymore in the java 8 runtime, even if they are defined in\nprevious versions of the app engine api jar"}
{"source":"gcp","filename":"appengine_docs_standard_java_java8_runtime_faq","question":"can i do traffic splitting between java 8 and java 11?","answer":"yes, each service or module version can use a different runtime version, and\ntraffic splitting is supported"}
{"source":"gcp","filename":"appengine_docs_standard_java_java8_runtime_faq","question":"how are java 8 threads treated when an instance isn't getting requests?","answer":"threads created with app engine apis will continue to work as before"}
{"source":"gcp","filename":"appengine_docs_standard_java_java8_runtime_faq","question":"why do my requests fail to respond?","answer":"if you create a thread pool on a request, you must make sure that you explicitly\nshut it down before the current request terminates"}
{"source":"gcp","filename":"spanner_docs_open_source_jdbc","question":"can i use this driver to issue data manipulation language (dml) and data definition language (ddl) statements?","answer":"yes, this driver supports dml and ddl statements"}
{"source":"gcp","filename":"spanner_docs_open_source_jdbc","question":"how does this driver deal with cloud spanner parent-child or interleaved table relationships?","answer":"interleaved table relationships are mapped to foreign key relationships in jdbc"}
{"source":"gcp","filename":"spanner_docs_open_source_jdbc","question":"are all cloud spanner data types supported by this driver?","answer":"the open-source jdbc driver does not support cloud spanner's struct data\ntype"}
{"source":"gcp","filename":"spanner_docs_open_source_jdbc","question":"does this driver support indexes?","answer":"yes, you can use indexes in select queries using the appropriate\nquery syntax"}
{"source":"gcp","filename":"spanner_docs_open_source_jdbc","question":"does this driver support parameterized queries?","answer":"yes, this driver supports positional parameterization"}
{"source":"gcp","filename":"spanner_docs_open_source_jdbc","question":"do i need to provide my own connection pool?","answer":"the open-source jdbc driver handles pooling internally by keeping track of all\nconnections that have been opened, as well as the connection properties that\nwere used to open those connections"}
{"source":"gcp","filename":"spanner_docs_open_source_jdbc","question":"are there other limitations to consider when using this driver?","answer":"this driver's capabilities have limits defined by the underlying system"}
{"source":"gcp","filename":"spanner_docs_open_source_jdbc","question":"how do i get support for this driver?","answer":"consult our support page for support options"}
{"source":"gcp","filename":"sql_docs_postgres_faq","question":"can i connect from app engine to a postgresql instance?","answer":"you can connect from an app engine application to a postgresql instance, depending on\n    the environment and language you are using"}
{"source":"gcp","filename":"docs_android_troubleshooting_faq_hl_ro","question":"do i need to provide a sha-1 when adding an android app to a firebase\n    project?","answer":"sha-1 information\n    is required by firebase authentication (when using\n    google signin or\n    phone number signin) and\n    firebase dynamic links"}
{"source":"gcp","filename":"docs_android_troubleshooting_faq_hl_ro","question":"how do i resolve this error: \"an oauth2 client already exists for this\n    package name and sha-1 in another project\"?","answer":"this error occurs if we detect that another firebase or google cloud\n    project contains an oauth 2"}
{"source":"gcp","filename":"memorystore_docs_redis_faq","question":"how long does a failover take for a standard tier redis instance?","answer":"a failover normally takes around 30 seconds to complete"}
{"source":"gcp","filename":"memorystore_docs_redis_faq","question":"what is the difference between basic tier and standard tier for memorystore for redis?","answer":"a basic tier instance is a standalone cache that is used for applications that can withstand an\n  occasional cold restart\/full data flush"}
{"source":"gcp","filename":"memorystore_docs_redis_faq","question":"is scale out cluster available on memorystore for redis?","answer":"no, memorystore for redis basic and standard tier both use a single primary node to store all\nredis data"}
{"source":"gcp","filename":"memorystore_docs_redis_faq","question":"can i use a client library that isn\u2019t listed on the \n  client libraries page?","answer":"yes, memorystore for redis is compatible with any client library for redis"}
{"source":"gcp","filename":"memorystore_docs_redis_faq","question":"can i use a shared vpc?","answer":"yes, shared vpc is supported for memorystore for redis"}
{"source":"gcp","filename":"memorystore_docs_redis_faq","question":"is persistence supported?","answer":"no, memorystore for redis does not currently support persistence"}
{"source":"gcp","filename":"memorystore_docs_redis_faq","question":"can i connect to a redis instance using the app engine standard environment?","answer":"yes, but first you need to connect the app engine standard environment to your vpc network"}
{"source":"gcp","filename":"memorystore_docs_redis_faq","question":"can i connect to a redis instance using cloud functions?","answer":"yes, but first you need to connect cloud functions to your vpc network"}
{"source":"gcp","filename":"memorystore_docs_redis_faq","question":"does memorystore for redis use open source redis, also known as oss redis?","answer":"yes, memorystore for redis uses open source redis"}
{"source":"gcp","filename":"memorystore_docs_redis_faq","question":"what version of redis is currently supported?","answer":"memorystore for redis currently supports redis versions 5"}
{"source":"gcp","filename":"memorystore_docs_redis_faq","question":"gcloud redis isn\u2019t working on the command line. why?","answer":"you may have an older version of gcloud installed"}
{"source":"gcp","filename":"database_migration_docs_mysql_faq","question":"what is database migration service?","answer":"database migration service is a service that makes it easy to migrate your on-premises relational\ndatabases to cloud sql"}
{"source":"gcp","filename":"database_migration_docs_mysql_faq","question":"what sources are supported?","answer":"rds 5,6, 5"}
{"source":"gcp","filename":"database_migration_docs_mysql_faq","question":"what destinations are supported?","answer":"cloud sql for mysql 5"}
{"source":"gcp","filename":"database_migration_docs_mysql_faq","question":"is there cross-version support?","answer":"database migration service supports mysql-to-cloud sql migrations across any major version, where the destination is the same version or one version higher than the source database"}
{"source":"gcp","filename":"database_migration_docs_mysql_faq","question":"what data, schema, and metadata components are migrated?","answer":"database migration service migrates schema, data, and metadata from the source to the destination"}
{"source":"gcp","filename":"database_migration_docs_mysql_faq","question":"what changes are replicated during continuous migration?","answer":"dml and ddl changes (that is, changes to all data, schema, and metadata listed above) are updated during\ncontinuous migrations"}
{"source":"gcp","filename":"database_migration_docs_mysql_faq","question":"what isn't migrated?","answer":"when migrating a mysql database, the mysql system databases which contain information about users\nand privileges aren't migrated"}
{"source":"gcp","filename":"database_migration_docs_mysql_faq","question":"what networking methods are used?","answer":"to create a migration in database migration service, connectivity must be established\nbetween the source and the cloud sql destination instance"}
{"source":"gcp","filename":"database_migration_docs_mysql_faq","question":"what are the known limitations?","answer":"see known limitations"}
{"source":"gcp","filename":"apigee_docs_support_portal_faqs","question":"how can i get access to google cloud apigee support portal?","answer":"you can find instructions on how to access apigee support portal in\n    access to support portal"}
{"source":"gcp","filename":"apigee_docs_support_portal_faqs","question":"i have forgotten my password for my apigee support portal account, how can i restore or reset it?","answer":"from the apigee support portal login page,\n    click forgot your password?"}
{"source":"gcp","filename":"apigee_docs_support_portal_faqs","question":"why am i seeing only the cases created by me and not the cases created by my team?","answer":"you likely have the role overage customer portal manager - user which allows you to see\n    only your cases"}
{"source":"gcp","filename":"apigee_docs_support_portal_faqs","question":"how can i see what role\/permissions i have?","answer":"the support portal administrator of your company will be able to tell you what role you\n    have been assigned"}
{"source":"gcp","filename":"apigee_docs_support_portal_faqs","question":"can i add new support portal users?","answer":"yes, you can find instructions on how to add new support portal users in\n    \n      adding more users to the support portal"}
{"source":"gcp","filename":"apigee_docs_support_portal_faqs","question":"one of the employees has left the company, can we remove that user from apigee support portal?","answer":"yes, you can find instructions to remove the user in\n    \n      remove users from support portal"}
{"source":"gcp","filename":"apigee_docs_support_portal_faqs","question":"i am a partner and would be helping in creating and managing cases for an apigee customer. can\n  i get access to apigee support portal?","answer":"yes, the support portal admin from the customer side can add the relevant partner team members\n    to apigee support portal"}
{"source":"gcp","filename":"apigee_docs_support_portal_faqs","question":"is there any limit on the number of support portal users that can be added for a particular\n  customer account? if the customer requests an increase in the number, do you charge them?","answer":"we do not impose a limit on the number of support users, though we do recommend that you keep\n    the number of contacts to those that are knowledgeable of and work on the apigee product"}
{"source":"gcp","filename":"apigee_docs_support_portal_faqs","question":"once the customer nominates a partner to raise cases on their behalf, is there a limit to the\n  number of partner people who could raise cases? again, if they want to increase the number of\n  partner people to have access to the support portal, is there a cost?","answer":"we do not impose a limit on the number of support users"}
{"source":"gcp","filename":"apigee_docs_support_portal_faqs","question":"i have a free trial account, can i get access to apigee support portal and raise support cases?","answer":"unfortunately no, however, if you do have questions about or issues with apigee products, you\n    can find answers to your questions, and can post questions in the\n    apigee community, where\n    apigee engineers are able to respond"}
{"source":"gcp","filename":"service_mesh_docs_migrate_istio_faq","question":"why should i migrate from istio to anthos service mesh?","answer":"anthos service mesh is google's managed and supported service mesh\nproduct powered by istio apis"}
{"source":"gcp","filename":"service_mesh_docs_migrate_istio_faq","question":"is there any downtime associated with this migration?","answer":"the script installs anthos service mesh as a\ncanary control plane \nalongside your existing istio control plane"}
{"source":"gcp","filename":"service_mesh_docs_migrate_istio_faq","question":"after i migrate to anthos service mesh, can i migrate back to istio?","answer":"yes, there is no commitment to use anthos service mesh"}
{"source":"gcp","filename":"service_mesh_docs_migrate_istio_faq","question":"if the migration fails, is it possible to roll back?","answer":"yes, the script lets you roll back to your previous istio version"}
{"source":"gcp","filename":"service_mesh_docs_migrate_istio_faq","question":"does migrating change my current istio configurations?","answer":"no, your istio configurations work on anthos service mesh without requiring any\nchanges"}
{"source":"gcp","filename":"service_mesh_docs_migrate_istio_faq","question":"are there any istio features that are not supported in anthos service mesh?","answer":"yes, you can learn about anthos service mesh features at\nin-cluster control plane supported features or\ngoogle-managed control plane supported features"}
{"source":"gcp","filename":"service_mesh_docs_migrate_istio_faq","question":"why did the tool install an in-cluster control plane?","answer":"to migrate to google-managed control plane, your gkemust be in a\nsupported region and be compatible with anthos service mesh 1"}
{"source":"gcp","filename":"service_mesh_docs_migrate_istio_faq","question":"will this migration work with my multi-cluster setup?","answer":"the script lets you migrate one cluster at a time to anthos service mesh"}
{"source":"gcp","filename":"service_mesh_docs_migrate_istio_faq","question":"which version of istio can i migrate by using this script?","answer":"you can migrate any istio version 1"}
{"source":"gcp","filename":"service_mesh_docs_migrate_istio_faq","question":"how can i get additional help with this migration?","answer":"our support tses are glad to help"}
{"source":"gcp","filename":"kms_docs_faq","question":"what is cloud kms? what can it do?","answer":"cloud key management service (cloud kms) is a cloud-hosted key management service that lets you\nmanage encryption for your cloud services the same way you do on-premises"}
{"source":"gcp","filename":"kms_docs_faq","question":"can i store secrets?","answer":"cloud kms stores keys and metadata about keys, and does not\nhave a general data storage api"}
{"source":"gcp","filename":"kms_docs_faq","question":"is there an sla?","answer":"yes, see cloud kms service level agreement"}
{"source":"gcp","filename":"kms_docs_faq","question":"how do i provide product feedback?","answer":"contact the engineering team at cloudkms-feedback@google"}
{"source":"gcp","filename":"kms_docs_faq","question":"how do i provide documentation feedback?","answer":"while viewing cloud kms documentation, click send feedback near\nthe top right of the page"}
{"source":"gcp","filename":"kms_docs_faq","question":"if i need help, what are my options?","answer":"we invite our users to post their questions on stack overflow"}
{"source":"gcp","filename":"kms_docs_faq","question":"does cloud kms have any quotas?","answer":"yes, for information about quotas, including viewing or requesting additional\nquotas, see cloud kms quotas"}
{"source":"gcp","filename":"kms_docs_faq","question":"in what countries can i use cloud kms?","answer":"you can use cloud kms in any country where google cloud services\nare supported"}
{"source":"gcp","filename":"kms_docs_faq","question":"what kinds of key does cloud kms generate?","answer":"see key purposes and algorithms"}
{"source":"gcp","filename":"kms_docs_faq","question":"are keys stored in an hsm?","answer":"keys with protection level hsm are stored in a hardware security module\n(hsm)"}
{"source":"gcp","filename":"kms_docs_faq","question":"to what standards do the keys comply?","answer":"keys generated in cloud kms and the cryptographic operations\nperformed with those keys comply with federal information processing standard\n(fips) publication security requirements for cryptographic modules\n140-2"}
{"source":"gcp","filename":"kms_docs_faq","question":"how is key material generated?","answer":"cloud kms software-protected keys are generated using google\u2019s\ncommon cryptographic library using a random number generator (rng) built by\ngoogle"}
{"source":"gcp","filename":"kms_docs_faq","question":"which library is used to generate key material?","answer":"cloud kms keys are generated using google\u2019s common cryptographic\nlibrary which implements cryptographic algorithms using boringssl"}
{"source":"gcp","filename":"kms_docs_faq","question":"are keys constrained to a geographic location?","answer":"keys belong to a region, but are not constrained to that region"}
{"source":"gcp","filename":"kms_docs_faq","question":"can i auto-rotate keys?","answer":"for keys used for symmetric encryption, yes"}
{"source":"gcp","filename":"kms_docs_faq","question":"does key rotation re-encrypt data? if not, why?","answer":"key rotation does not automatically re-encrypt data"}
{"source":"gcp","filename":"kms_docs_faq","question":"why can't i delete keys or key rings?","answer":"to prevent resource name collisions, key ring and key resources cannot be\ndeleted"}
{"source":"gcp","filename":"kms_docs_faq","question":"can i export keys?","answer":"no, keys are not exportable from cloud kms by design"}
{"source":"gcp","filename":"kms_docs_faq","question":"can i import keys?","answer":"yes, you can import only into keys with protection level hsm or software"}
{"source":"gcp","filename":"kms_docs_faq","question":"how long after i destroy a key version can i get it back?","answer":"after you schedule a key version for destruction, you have 24 hours before the\nkey version is actually destroyed"}
{"source":"gcp","filename":"kms_docs_faq","question":"when i make changes to a key, how quickly do the changes take effect?","answer":"some operations to cloud kms resources are strongly consistent,\nwhile others are eventually consistent and may take up to 3 hours to propagate"}
{"source":"gcp","filename":"kms_docs_faq","question":"why is my key in pending_generation state?","answer":"due to the cpu cost of generating key material, creation of an asymmetric\nsigning or asymmetric encryption key version may take a few minutes"}
{"source":"gcp","filename":"kms_docs_faq","question":"how do i authenticate to the cloud kms api?","answer":"how clients authenticate may vary a bit depending on the platform on which the\ncode is running"}
{"source":"gcp","filename":"kms_docs_faq","question":"what iam roles should i use?","answer":"to enforce the principle of least privilege, ensure that the user and service\naccounts in your organization have only the permissions essential to performing\ntheir intended functions"}
{"source":"gcp","filename":"kms_docs_faq","question":"how quickly is an iam permission removed?","answer":"removal of a permission should be in effect in less than one hour"}
{"source":"gcp","filename":"kms_docs_faq","question":"what is additional authenticated data, and when would i use it?","answer":"additional authenticated data (aad) is any string that you pass to\ncloud kms as part of an encrypt or decrypt request"}
{"source":"gcp","filename":"kms_docs_faq","question":"are data access logs enabled by default? how do i enable data access logs?","answer":"data access logs are not enabled by default"}
{"source":"gcp","filename":"kms_docs_faq","question":"how do cloud kms keys relate to service account keys?","answer":"service account keys are used for service-to-service authentication within\ngoogle cloud"}
{"source":"gcp","filename":"kms_docs_faq","question":"how do cloud kms keys relate to api keys?","answer":"an api key is a simple encrypted string that can be used when calling\ncertain apis that don't need access to private user data"}
{"source":"gcp","filename":"network_intelligence_center_docs_connectivity_tests_support_faq","question":"can i test a configuration where i enabled the forwarding functions of my vm instance?","answer":"no, the configuration analysis traces a packet based on the configuration of\nresources in your google cloud projects"}
{"source":"gcp","filename":"network_intelligence_center_docs_connectivity_tests_support_faq","question":"the configuration analysis can produce multiple traces for a given test; how does dynamic verification handle such tests?","answer":"dynamic verification does not provide a breakdown into multiple traces"}
{"source":"gcp","filename":"speech_to_text_docs_data_usage_faq","question":"does google use the text or audio i send to the speech-to-text api?","answer":"if you are not enrolled in the\ndata logging opt-in program, google\ndoes not use any of your content for any purpose except to provide you with\nthe speech-to-text api service"}
{"source":"gcp","filename":"speech_to_text_docs_data_usage_faq","question":"will google share the audio i send to the speech-to-text api?","answer":"google does not make the audio content sent to the speech-to-text api\navailable to anyone else except as necessary to provide the speech-to-text api\nservice"}
{"source":"gcp","filename":"speech_to_text_docs_data_usage_faq","question":"will the audio i send to the speech-to-text api, the transcription results,\nor other information about the request itself, be stored on google servers?\nif so, for how long and where is the information kept, and do i have access\nto it?","answer":"when you send audio to the speech-to-text api streaming or sync endpoints,\ngoogle processes it in memory and does not store any customer data"}
{"source":"gcp","filename":"speech_to_text_docs_data_usage_faq","question":"how does google protect and ensure the security of the data i send to the\nspeech-to-text api?","answer":"please refer to the\ngoogle cloud platform security page,\nwhich describes the security measures in place for google's cloud services"}
{"source":"gcp","filename":"speech_to_text_docs_data_usage_faq","question":"does google use my data to improve speech-to-text api services?","answer":"google only uses data from customers who have opted in to\ndata logging and agreed to the relevant\nterms to improve its services"}
{"source":"gcp","filename":"speech_to_text_docs_data_usage_faq","question":"where is data sent to the speech-to-text api processed?","answer":"data sent to speech-to-text is processed globally"}
{"source":"gcp","filename":"speech_to_text_docs_data_usage_faq","question":"does google claim ownership of the content i send in the request to the\nspeech-to-text api?","answer":"google does not claim any ownership in any of the content (including the\naudio data and returned transcript) that you transmit to the speech-to-text api"}
{"source":"gcp","filename":"speech_to_text_docs_data_usage_faq","question":"can i resell the speech-to-text api?","answer":"no, you are not permitted to resell the speech-to-text api service"}
{"source":"gcp","filename":"iam_docs_faq","question":"what is iam?","answer":"iam enables you to create and manage permissions for\ngoogle cloud resources"}
{"source":"gcp","filename":"iam_docs_faq","question":"why do i need iam?","answer":"iam lets you adopt the\nsecurity principle of least privilege,\nso you grant only the necessary access to your resources and prevent unwanted\naccess to other resources"}
{"source":"gcp","filename":"iam_docs_faq","question":"which of the google cloud services support iam?","answer":"all google cloud services use iam to make sure that\nonly authorized identities can access them"}
{"source":"gcp","filename":"iam_docs_faq","question":"how do i get started with using iam?","answer":"to get started with iam, read\niam quickstart"}
{"source":"gcp","filename":"iam_docs_faq","question":"can i use iam policies to manage both authentication and authorization for my applications?","answer":"use iam to manage authorization to google cloud resources"}
{"source":"gcp","filename":"iam_docs_faq","question":"what is the relationship between a role and a policy?","answer":"permissions determine what operations are allowed on a resource"}
{"source":"gcp","filename":"iam_docs_faq","question":"what is the difference between basic roles and predefined roles?","answer":"basic roles are the legacy owner, editor, and viewer roles"}
{"source":"gcp","filename":"iam_docs_faq","question":"can i define my own (custom) roles?","answer":"yes, see the article on custom roles"}
{"source":"gcp","filename":"iam_docs_faq","question":"how can i find out what roles are granted on a resource?","answer":"you can find out what roles are granted on a resource by using the\ncloud console\n, the getiampolicy() method, or the gcloud command-line tool"}
{"source":"gcp","filename":"iam_docs_faq","question":"how can i create and manage my iam policies?","answer":"you can create and manage iam policies using the\ngoogle cloud console, the gcloud tool, and the iam\nmethods"}
{"source":"gcp","filename":"iam_docs_faq","question":"how can i find out my project's iam policy?","answer":"you can find out a project's iam policy by using the cloud console, the\nproject"}
{"source":"gcp","filename":"iam_docs_faq","question":"how can i find out my organization-level policy?","answer":"you can find the organization-level policy using the cloud console, the\norganization"}
{"source":"gcp","filename":"iam_docs_faq","question":"how do i update a policy?","answer":"you can update a policy by using the cloud console, the rest api, or\nthe gcloud tool"}
{"source":"gcp","filename":"iam_docs_faq","question":"are there limits on how many principals i can include in a policy?","answer":"yes, the number of principals in a policy is limited"}
{"source":"gcp","filename":"iam_docs_faq","question":"how do i troubleshoot my policies?","answer":"you can use policy troubleshooter to check if a\nprincipal has a certain permission on a resource"}
{"source":"gcp","filename":"iam_docs_faq","question":"can i use google groups with iam?","answer":"usually, one exception is the owner role"}
{"source":"gcp","filename":"iam_docs_faq","question":"can i use iam to create and manage my users?","answer":"no, you can use\ncloud identity or\ngoogle workspace\nto create and manage users"}
{"source":"gcp","filename":"iam_docs_faq","question":"how can i disable a user's access to iam resources?","answer":"if you granted the user the iam role via a google group, you can remove the user\nfrom the group and they'll no longer have the access you granted to the group"}
{"source":"gcp","filename":"iam_docs_faq","question":"why can a user not access resources shortly after permission is granted, or continue to access resources after permission is removed?","answer":"in general, it takes fewer than 60 seconds for a principal's\naccess to be granted or revoked"}
{"source":"gcp","filename":"iam_docs_faq","question":"how do i grant permissions to resources in my project to someone who is not part of my organization?","answer":"using google groups, you can add a user outside of your organization to a group\nand bind that group to the role"}
{"source":"gcp","filename":"iam_docs_faq","question":"how can i manage who can access my instances?","answer":"to manage who has access to your instances, use google groups to bind identities\nto roles"}
{"source":"gcp","filename":"iam_docs_faq","question":"how can i use multi factor authentication (mfa) with iam?","answer":"when individual users use mfa, the methods they authenticate with will be\nhonored"}
{"source":"gcp","filename":"iam_docs_faq","question":"how does a service account differ from a user who uses iam?","answer":"a service account is a special google account that can be used by applications\nto access google services programmatically"}
{"source":"gcp","filename":"iam_docs_faq","question":"what is the maximum number of service accounts i can have in a project?","answer":"by default, you can create up to 100 service accounts in\na project"}
{"source":"gcp","filename":"iam_docs_faq","question":"how can i rotate the service account keys when using iam?","answer":"the google cloud-managed keys are rotated daily"}
{"source":"gcp","filename":"iam_docs_faq","question":"how do i control who can create a service account in my project?","answer":"owner and editor roles have permissions to create service accounts in a\nproject"}
{"source":"gcp","filename":"iam_docs_faq","question":"can i create a service account under an organization?","answer":"currently you can create service accounts only under a project; you cannot\ncreate a service account directly under an organization"}
{"source":"gcp","filename":"iam_docs_faq","question":"i have a dedicated team that manages network and firewall rules. how can i maintain this separation of duty so that my development teams can manage instances but not make any network or firewall changes?","answer":"first, grant the compute network admin\nrole at the organization or the project level to your network administrators"}
{"source":"gcp","filename":"iam_docs_faq","question":"i need to ensure that the teams in my organization cannot access each other's instances. how can i do this?","answer":"create two projects one for each team"}
{"source":"gcp","filename":"iam_docs_faq","question":"can i change the service account that i use to launch my instance?","answer":"yes, however you cannot change the service account for a running\ncompute engine instance"}
{"source":"gcp","filename":"iam_docs_faq","question":"in what scenarios would i use the service account actor role?","answer":"the service account actor role has been deprecated"}
{"source":"gcp","filename":"iam_docs_faq","question":"in what scenarios would i use the service account user role?","answer":"the service account user\ngives permissions to run operations as the service account"}
{"source":"gcp","filename":"iam_docs_faq","question":"how can i audit my iam policies?","answer":"you can use cloud audit logs to regularly audit changes\nto your iam policy"}
{"source":"gcp","filename":"iam_docs_faq","question":"how can i control who has access to my audit logs?","answer":"you can control access to logs using\ncloud logging roles"}
{"source":"gcp","filename":"iam_docs_faq","question":"how do i persist my audit logs?","answer":"individual audit log entries are kept for a specified length of time and are\nthen deleted"}
{"source":"gcp","filename":"video_intelligence_docs_data_usage","question":"does google use the video i send to the video intelligence api?","answer":"google does not use any of your content (such as videos and\n    labels) for any purpose except to provide you with the video intelligence api\n    service"}
{"source":"gcp","filename":"video_intelligence_docs_data_usage","question":"will google share the video i send to the video intelligence api?","answer":"we will not make the video that you send available to the public, or share\n    it with anyone else, except as necessary to provide the video intelligence api\n    service"}
{"source":"gcp","filename":"video_intelligence_docs_data_usage","question":"will the video i send to the video intelligence api, the results or other\n    information about the request itself, be stored on google servers? if so,\n    how long and where is the information kept, and do i have access to it?","answer":"when you send a video to the video intelligence api, we must store that\n    video for a short period of time in order to perform the analysis and return\n    the results to you"}
{"source":"gcp","filename":"video_intelligence_docs_data_usage","question":"how does google protect and ensure the security of the data i send to the\n    video intelligence api?","answer":"please refer to the google cloud platform security\n    page which describes the security measures in place for google\u2019s cloud\n    services"}
{"source":"gcp","filename":"video_intelligence_docs_data_usage","question":"does google use my data for improving google video intelligence api?","answer":"currently, google does not use the content you send to train and improve\n  our google video intelligence features such as its machine perception model"}
{"source":"gcp","filename":"video_intelligence_docs_data_usage","question":"does google claim ownership of the content i send in the request to the\n    video intelligence api?","answer":"google does not claim any ownership in any of the content (including\n    videos and labels) that you transmit to the video intelligence api"}
{"source":"gcp","filename":"video_intelligence_docs_data_usage","question":"can i resell the video intelligence api?","answer":"no, you are not permitted to resell the video intelligence api service"}
{"source":"gcp","filename":"document_ai_docs_data_usage","question":"does google use the document i send to the document ai api?","answer":"google does not use any of your content (such as documents and\n    predictions) for any purpose except to provide you with the document ai api\n    service"}
{"source":"gcp","filename":"document_ai_docs_data_usage","question":"will google share the document i send to the document ai api?","answer":"we will not make the document that you send available to the public, or share\n    it with anyone else, except as necessary to provide the document ai api\n    service"}
{"source":"gcp","filename":"document_ai_docs_data_usage","question":"will the document i send to the document ai api, the results or other\n    information about the request itself, be stored on google servers? if so,\n    how long and where is the information kept, and do i have access to it?","answer":"when you send an document to document ai api, we must store that\n    document for a short period of time in order to perform the analysis and return\n    the results to you"}
{"source":"gcp","filename":"document_ai_docs_data_usage","question":"how does google protect and ensure the security of the data i send to\n    document ai api?","answer":"please refer to the google cloud platform security\n    page which describes the security measures in place for google's cloud\n    services"}
{"source":"gcp","filename":"document_ai_docs_data_usage","question":"does google use my data for improving document ai?","answer":"currently, google does not use the content you send to train and improve\n  our document ai features such as its machine perception model"}
{"source":"gcp","filename":"document_ai_docs_data_usage","question":"does google claim ownership of the content i send in the request to\n    document ai api?","answer":"google does not claim any ownership in any of the content (including\n    documents and predictions) that you transmit to the document ai api"}
{"source":"gcp","filename":"document_ai_docs_data_usage","question":"can i resell the document ai api?","answer":"no, you are not permitted to resell the document ai api service"}
{"source":"gcp","filename":"vision_docs_data_usage","question":"does google use the image i send to the vision api?","answer":"google does not use any of your content (such as images and\n    labels) for any purpose except to provide you with the vision api\n    service"}
{"source":"gcp","filename":"vision_docs_data_usage","question":"will google share the image i send to the vision api?","answer":"we will not make the image that you send available to the public, or share\n    it with anyone else, except as necessary to provide the vision api\n    service"}
{"source":"gcp","filename":"vision_docs_data_usage","question":"will the image i send to the vision api, the results or other\n    information about the request itself, be stored on google servers? if so,\n    how long and where is the information kept, and do i have access to it?","answer":"when you send an image to vision api, we must store that\n    image for a short period of time in order to perform the analysis and return\n    the results to you"}
{"source":"gcp","filename":"vision_docs_data_usage","question":"does google use my data for improving cloud vision?","answer":"currently, google does not use the content you send to train and improve\n  our cloud vision features such as its machine perception model"}
{"source":"gcp","filename":"vision_docs_data_usage","question":"does google claim ownership of the content i send in the request to\n    vision api?","answer":"google does not claim any ownership in any of the content that you\n    transmit to the vision api"}
{"source":"gcp","filename":"vision_docs_data_usage","question":"can i resell the vision api?","answer":"no, you are not permitted to resell the vision api service"}
{"source":"gcp","filename":"dataflow_docs_resources_faq","question":"where can i find additional support?","answer":"you can visit google cloud support to obtain\na support package for google cloud, including dataflow"}
{"source":"gcp","filename":"dataflow_docs_resources_faq","question":"is it possible to share data across pipeline instances?","answer":"there is no dataflow-specific cross pipeline communication\nmechanism for sharing data or processing context between pipelines"}
{"source":"gcp","filename":"dataflow_docs_resources_faq","question":"how can i tell what version of the dataflow sdk is installed\/running in my environment?","answer":"installation details depend on your development environment"}
{"source":"gcp","filename":"dataflow_docs_resources_faq","question":"how many instances of dofn should i expect dataflow to spin up ?","answer":"it is hard to estimate how many instances of a\ndofn\ndataflow creates as it depends on a number of factors like the sdk, machine type\netc"}
{"source":"gcp","filename":"dataflow_docs_resources_faq","question":"is it possible to access my job's worker machines (compute engine vms) while my pipeline is running?","answer":"you can view the vm instances for a given pipeline by using the\ngoogle cloud console"}
{"source":"gcp","filename":"dataflow_docs_resources_faq","question":"in the cloud dataflow monitoring interface, why don't i see reserved cpu time for my streaming job?","answer":"the dataflow service reports reserved cpu time after jobs are\ncompleted"}
{"source":"gcp","filename":"dataflow_docs_resources_faq","question":"in the cloud dataflow monitoring interface, why are the job state and watermark information unavailable for recently updated streaming jobs?","answer":"the update operation makes several changes that take a few minutes to propagate\nto the dataflow monitoring interface"}
{"source":"gcp","filename":"dataflow_docs_resources_faq","question":"why can't i see my ongoing job's information anymore in the cloud dataflow monitoring interface, even though it appeared previously?","answer":"there is a known issue that currently can affect some dataflow\njobs that have been running for one month or longer"}
{"source":"gcp","filename":"dataflow_docs_resources_faq","question":"how are java exceptions handled in cloud dataflow?","answer":"your pipeline may throw exceptions while processing data"}
{"source":"gcp","filename":"dataflow_docs_resources_faq","question":"does the textio source and sink support compressed files, such as gzip?","answer":"yes, dataflow java can read files compressed with gzip and\nbzip2"}
{"source":"gcp","filename":"dataflow_docs_resources_faq","question":"can i use a regular expression to target specific files with the textio source?","answer":"dataflow supports general wildcard patterns; your glob expression\ncan appear anywhere in the file path"}
{"source":"gcp","filename":"dataflow_docs_resources_faq","question":"does the textio input source support json?","answer":"yes, however, for the dataflow service to be able to\nparallelize input and\noutput, your source data must be delimited with a line feed"}
{"source":"gcp","filename":"dataflow_docs_resources_faq","question":"why isn't dynamic work rebalancing activating with my custom source?","answer":"dynamic work rebalancing uses the return value of your custom source's getprogress()\nmethod to activate"}
{"source":"gcp","filename":"dataflow_docs_resources_faq","question":"how do i access bigquery datasets or pub\/sub topics or subscriptions owned by a different google cloud platform project (i.e., not the project with which i'm using cloud dataflow)?","answer":"see dataflow's security and\npermissions guide for\ninformation on how to access bigquery or pub\/sub\ndata in a different google cloud project than the one with which you're\nusing dataflow"}
{"source":"gcp","filename":"dataflow_docs_resources_faq","question":"why do i get \"ratelimitexceeded\" errors when using the bigquery connector and what should i do about them?","answer":"bigquery has short term quota limits that apply when too many\napi requests \nare sent during a short duration"}
{"source":"gcp","filename":"dataflow_docs_resources_faq","question":"i'm using the bigquery connector to write to bigquery using streaming inserts and my write throughput is lower than expected. what can i do to remedy this?","answer":"slow throughput might be due to your pipeline exceeding the available bigquery streaming insert quota"}
{"source":"gcp","filename":"dataflow_docs_resources_faq","question":"how do i run my pipeline in streaming mode?","answer":"you can set the --streaming flag at the\ncommand line\nwhen you execute your pipeline"}
{"source":"gcp","filename":"dataflow_docs_resources_faq","question":"what data sources and sinks are supported in streaming mode?","answer":"you can read streaming data from pub\/sub, and you can write\nstreaming data to pub\/sub or bigquery"}
{"source":"gcp","filename":"dataflow_docs_resources_faq","question":"what are the current limitations of streaming mode?","answer":"batch sources are not yet supported in streaming mode"}
{"source":"gcp","filename":"dataflow_docs_resources_faq","question":"why isn't my streaming job upscaling properly when i update my pipeline with a larger pool of workers?","answer":"to enable streaming autoscaling, you need to opt in; it's not on by default"}
{"source":"gcp","filename":"dataflow_docs_resources_faq","question":"how do i make a bucket owned by a different project readable or writable for the google cloud platform project i'm using with cloud dataflow?","answer":"see dataflow's security and\npermissions\nguide for information on how your dataflow pipeline can access\ngoogle cloud resources owned by a different google cloud project"}
{"source":"gcp","filename":"recaptcha_enterprise_docs_faq_hl_fa","question":"can i use recaptcha enterprise globally?","answer":"yes, please use www,recaptcha"}
{"source":"gcp","filename":"recaptcha_enterprise_docs_faq_hl_fa","question":"does recaptcha enterprise use cookies?","answer":"recaptcha enterprise sets a necessary cookie (_grecaptcha) when executed for the purpose of providing its risk analysis"}
{"source":"gcp","filename":"recaptcha_enterprise_docs_faq_hl_fa","question":"i'd like to use the score from recaptcha enterprise to show a challenge \/ checkbox widget. how can i do this?","answer":"we recommend that you do not do this"}
{"source":"gcp","filename":"recaptcha_enterprise_docs_faq_hl_fa","question":"can i customize the recaptcha enterprise widget or badge?","answer":"yes, recaptcha enterprise offers light and dark themes, as shown below"}
{"source":"gcp","filename":"recaptcha_enterprise_docs_faq_hl_fa","question":"how many domains can i add in the \"verify domains\" list in google cloud console?","answer":"there is a limit of 250 domains per site key"}
{"source":"gcp","filename":"recaptcha_enterprise_docs_faq_hl_fa","question":"in the recaptcha enterprise dashboard, what timezone is used? can i change this?","answer":"this timezone is based on the client timezone of your browser"}
{"source":"gcp","filename":"recaptcha_enterprise_docs_faq_hl_fa","question":"i'd like to run automated tests with recaptcha enterprise. what should i do?","answer":"you can create recaptcha enterprise site keys designed for testing by using\nthe gcloud command-line tool"}
{"source":"gcp","filename":"recaptcha_enterprise_docs_faq_hl_fa","question":"i'd like to communicate with the recaptcha enterprise rest api. can i assume that the response format will not change in the future?","answer":"as our product evolves, we might apply\nnon-breaking changes\nlike adding new fields to our api"}
{"source":"gcp","filename":"recaptcha_enterprise_docs_faq_hl_fa","question":"what session data is collected by recaptcha enterprise and how does google protect it?","answer":"for information about the details collected by recaptcha enterprise, privacy policy, and terms, see terms of service"}
{"source":"gcp","filename":"managed_microsoft_ad_docs_faq","question":"what user do i use to manage managed microsoft ad?","answer":"when setting up managed microsoft ad, a\ndelegated administrator account is created to\nmanage managed microsoft ad"}
{"source":"gcp","filename":"managed_microsoft_ad_docs_faq","question":"how can i manage organizational units (ou)?","answer":"managed microsoft ad creates the cloud and cloud service objects ou"}
{"source":"gcp","filename":"managed_microsoft_ad_docs_faq","question":"how can i manage group policy objects (gpo)?","answer":"by default, managed microsoft ad creates the cloud service default computer\npolicy gpo and links it to the cloud ou"}
{"source":"gcp","filename":"managed_microsoft_ad_docs_faq","question":"how are domain controllers deployed?","answer":"domain controllers are created as vms in dedicated\nvirtual private cloud (vpc) networks"}
{"source":"gcp","filename":"managed_microsoft_ad_docs_faq","question":"when i create a new managed microsoft ad domain, what ip range should i choose?","answer":"managed microsoft ad requires a minimum of \/24 range, such as 10"}
{"source":"gcp","filename":"managed_microsoft_ad_docs_faq","question":"where can i view the domain controller event logs?","answer":"you can use\nmanaged microsoft ad audit logs"}
{"source":"gcp","filename":"managed_microsoft_ad_docs_faq","question":"what should i expect during maintenance for a domain controller vm?","answer":"the ad domain remains available during patches and updates"}
{"source":"gcp","filename":"managed_microsoft_ad_docs_faq","question":"can i restore my active directory data after a failure?","answer":"managed microsoft ad supports on-demand and automatic domain backups"}
{"source":"gcp","filename":"managed_microsoft_ad_docs_faq","question":"can i extend the active directory directory service schema?","answer":"while extending the active directory schema for the managed microsoft ad\ndomain (forest) is not currently supported, managed microsoft ad can be\nused with existing active directory domains (forests) that have schema\nextensions"}
{"source":"gcp","filename":"managed_microsoft_ad_docs_faq","question":"what time server do managed microsoft ad domain controllers use?","answer":"managed microsoft ad domain controllers sync time from the\nmetadata"}
{"source":"gcp","filename":"managed_microsoft_ad_docs_faq","question":"do i need to a create a separate project for each managed microsoft ad domain?","answer":"no, you do not need separate google cloud projects"}
{"source":"gcp","filename":"natural_language_docs_data_usage","question":"does google look at or use the text i send to the cloud natural language api?","answer":"google does not use any of your content (such as text sent for\n    analysis) for any purpose except to provide you with the cloud natural\n    language api service"}
{"source":"gcp","filename":"natural_language_docs_data_usage","question":"will google share the text i send to the cloud natural language api?","answer":"we will not make the content of the text that you send available to the\n    public, or share it with anyone else, except as necessary to provide the\n    cloud natural language api service"}
{"source":"gcp","filename":"natural_language_docs_data_usage","question":"will the text i send to the cloud natural language api, the results, or other\n    information about the request itself, be stored on google servers? if so,\n    how long and where is the information kept, and do i have access to it?","answer":"when you send text to cloud natural language api, google processes it in memory and\n    does not store any customer data"}
{"source":"gcp","filename":"natural_language_docs_data_usage","question":"does google use my data for improving google natural language support?","answer":"currently, google does not use the content you send to train and improve\n  our google natural language features such as its machine analysis model"}
{"source":"gcp","filename":"natural_language_docs_data_usage","question":"does google claim ownership of the content i send in the request to the\n    cloud natural language api?","answer":"google does not claim any ownership in any of the content (including\n    text and labels) that you transmit to the cloud natural language api"}
{"source":"gcp","filename":"natural_language_docs_data_usage","question":"can i resell the cloud natural language api?","answer":"no, you are not permitted to resell the cloud natural language api\n    service"}
{"source":"gcp","filename":"composer_docs_concepts_overview","question":"what version of apache airflow does cloud composer use?","answer":"cloud composer supports both airflow 1 and airflow 2"}
{"source":"gcp","filename":"composer_docs_concepts_overview","question":"can i use native airflow ui and cli?","answer":"you can access the apache airflow web interface of your environment"}
{"source":"gcp","filename":"architecture_partners_netapp_cloud_volumes_faqs_netapp","question":"what is the data plane architecture for cloud volumes service for google cloud?","answer":"cloud volumes service for google cloud leverages the\ngoogle cloud\nprivate google access \nframework"}
{"source":"gcp","filename":"architecture_partners_netapp_cloud_volumes_faqs_netapp","question":"is the data in a cloud volume encrypted?","answer":"yes, data is encrypted at rest using netapp volume encryption (nve), which uses\naes 256-bit encryption that is\nfips 140-2 compliant"}
{"source":"gcp","filename":"architecture_partners_netapp_cloud_volumes_faqs_netapp","question":"is the data encrypted in transit between a cloud volume and a compute engine instance?","answer":"data traverses over standard google vpc constructs between a cloud volume and a\ncompute engine instance that inherit any in-transit encryption features\nprovided by those constructs"}
{"source":"gcp","filename":"architecture_partners_netapp_cloud_volumes_faqs_netapp","question":"how is access to the data in a cloud volume restricted to specific compute engine instances or users?","answer":"for nfs volumes, access to mount volumes is controlled by export policies"}
{"source":"gcp","filename":"architecture_partners_netapp_cloud_volumes_faqs_netapp","question":"are there iam controls to specify who can administer cloud volumes service?","answer":"yes, cloud volumes service provides granular permissions for all objects in the\ncloud volumes service api such as volumes, snapshots, and active directory"}
{"source":"gcp","filename":"architecture_partners_netapp_cloud_volumes_faqs_netapp","question":"why does the cloud volumes smb netbios name not reflect the name configured for the cloud volume?","answer":"cloud volumes service doesn't let you use more than 10 characters for the cloud\nvolumes smb netbios name"}
{"source":"gcp","filename":"architecture_partners_netapp_cloud_volumes_faqs_netapp","question":"why can't my client resolve the smb netbios name?","answer":"you can map\/mount an smb share created with cloud volumes service by using its\nuniform naming convention (unc) path, which the ui displays"}
{"source":"gcp","filename":"architecture_partners_netapp_cloud_volumes_faqs_netapp","question":"how can i check whether my smb share is using smb encryption?","answer":"when you map an smb share, the client and server negotiate the smb version and\nfeatures like smb encryption"}
{"source":"gcp","filename":"architecture_partners_netapp_cloud_volumes_faqs_netapp","question":"how can i identify active directory domain controllers used by the cvs and cvs-performance service types?","answer":"cloud volumes service uses\nactive directory connections \nto configure volumes of the cvs and cvs-performance service types"}
{"source":"gcp","filename":"architecture_partners_netapp_cloud_volumes_faqs_netapp","question":"is smb multichannel enabled by default in smb shares?","answer":"yes, smb multichannel is enabled by default"}
{"source":"gcp","filename":"architecture_partners_netapp_cloud_volumes_faqs_netapp","question":"does cloud volumes service support receive-side scaling (rss)?","answer":"with smb multichannel enabled, an smb3 client establishes multiple tcp\nconnections to the cloud volumes service smb server over a network interface\ncard (nic) that is single rss capable"}
{"source":"gcp","filename":"architecture_partners_netapp_cloud_volumes_faqs_netapp","question":"which windows versions support smb multichannel?","answer":"windows has supported smb multichannel since windows 2012"}
{"source":"gcp","filename":"architecture_partners_netapp_cloud_volumes_faqs_netapp","question":"does cloud volumes service for google cloud support smb direct?","answer":"no, smb direct is not currently supported"}
{"source":"gcp","filename":"architecture_partners_netapp_cloud_volumes_faqs_netapp","question":"what is the benefit of smb multichannel?","answer":"the smb multichannel feature enables an smb3 client to establish a pool of\nconnections over a single network interface card (nic) or multiple nics and to\nuse them to send requests for a single smb session"}
{"source":"gcp","filename":"architecture_partners_netapp_cloud_volumes_faqs_netapp","question":"is there value in configuring multiple nics on the smb client?","answer":"no, the smb client matches the nic count returned by the smb server"}
{"source":"gcp","filename":"architecture_partners_netapp_cloud_volumes_faqs_netapp","question":"is nic teaming supported in cloud volumes service for google cloud?","answer":"nic teaming is not supported in cloud volumes service for\ngoogle cloud"}
{"source":"gcp","filename":"architecture_partners_netapp_cloud_volumes_faqs_netapp","question":"what's the performance for smb multichannel?","answer":"the following tests and graphs demonstrate the power of smb multichannel on\nsingle-instance workloads"}
{"source":"gcp","filename":"architecture_partners_netapp_cloud_volumes_faqs_netapp","question":"what test parameters were used to produce the performance graphs above?","answer":"the following configuration file was used with the flexible io (fio) load\ngenerator"}
{"source":"gcp","filename":"architecture_partners_netapp_cloud_volumes_faqs_netapp","question":"what performance is expected with a single vm with a 1 tib dataset?","answer":"to provide more detailed insight into workloads with read\/write mixes, the\nfollowing two charts show the performance of a single, extreme service-level\ncloud volume of 50 tib with a 1 tib dataset and with an smb multichannel of 4"}
{"source":"gcp","filename":"architecture_partners_netapp_cloud_volumes_faqs_netapp","question":"what performance is expected when scaling out using 5 vms with a 1 tib dataset?","answer":"these tests with 5 vms use the same testing environment as the single vm, with\neach process writing to its own file"}
{"source":"gcp","filename":"architecture_partners_netapp_cloud_volumes_faqs_netapp","question":"how do you monitor virtio ethernet adapters and ensure that you maximize network capacity?","answer":"one strategy used in testing with fio is to set numjobs=16"}
{"source":"gcp","filename":"architecture_partners_netapp_cloud_volumes_faqs_netapp","question":"are jumbo frames supported?","answer":"jumbo frames are not supported with compute engine virtual machines"}
{"source":"gcp","filename":"architecture_partners_netapp_cloud_volumes_faqs_netapp","question":"what is smb signing, and is it supported by cloud volumes service for google cloud?","answer":"the smb protocol provides the basis for file and print sharing and other\nnetworking operations such as remote windows administration"}
{"source":"gcp","filename":"architecture_partners_netapp_cloud_volumes_faqs_netapp","question":"what is the performance impact of smb signing?","answer":"smb signing has a detrimental effect upon smb performance"}
{"source":"gcp","filename":"architecture_partners_netapp_cloud_volumes_faqs_netapp","question":"how do i determine if a directory is approaching the limit size?","answer":"you can use the stat command from a cloud volumes service client to see\nwhether a directory is approaching the maximum size limit (320 mb)"}
{"source":"gcp","filename":"architecture_partners_netapp_cloud_volumes_faqs_netapp","question":"will i be billed for accessing my cloud volume from a compute engine instance located in a different region or zone?","answer":"yes, standard google cloud inter-region data movement is charged according\nto the\ntransfer rates"}
{"source":"gcp","filename":"security_command_center_docs_faq","question":"can i limit who views which projects?","answer":"yes, permissions for security command center can be applied at the organization,\n    folder, and project level"}
{"source":"gcp","filename":"security_command_center_docs_faq","question":"how can i export data?","answer":"to export data from security command center, use the\n    api or the google cloud console"}
{"source":"gcp","filename":"security_command_center_docs_faq","question":"does security command center support more assets like\n    bigquery?","answer":"security command center supports discovery and inventory of\n    bigquery datasets"}
{"source":"gcp","filename":"security_command_center_docs_faq","question":"does security command center support alerting and setting alert policies?","answer":"the security command center api includes a notifications feature that sends\n      information to a pub\/sub topic to provide findings updates and new\n      findings within minutes"}
{"source":"gcp","filename":"security_command_center_docs_faq","question":"when are new features released, and when can we expect bug fixes?","answer":"security command center is in ga, so we release regular\n    bug fixes and functionality as available"}
{"source":"gcp","filename":"security_command_center_docs_faq","question":"how fresh is the data that's displayed in the security command center\n    dashboard?","answer":"data freshness depends on finding source and the time of the most recent\n    asset scan"}
{"source":"gcp","filename":"security_command_center_docs_faq","question":"why is the open_firewall module not producing findings for some of my\n    firewall rules containing the source ip range 0.0.0.0\/0 ?","answer":"your firewall rule may contain a destination port which explicitly does\n    not produce findings"}
{"source":"gcp","filename":"compute_docs_nodes_sole_tenancy_accounting_faq","question":"what are sole-tenant nodes?","answer":"normally, vms run on physical hosts that might be shared by many customers"}
{"source":"gcp","filename":"compute_docs_nodes_sole_tenancy_accounting_faq","question":"should i consider the purchase of a sole-tenant node as capex or opex?","answer":"google does not provide guidance about accounting"}
{"source":"gcp","filename":"compute_docs_nodes_sole_tenancy_accounting_faq","question":"what is the server_id?","answer":"the server_id is a unique identifier that is used to mark each\nphysical server"}
{"source":"gcp","filename":"compute_docs_nodes_sole_tenancy_accounting_faq","question":"will google cloud reuse the same server_id for different physical servers?","answer":"no, google cloud does not reuse the same server_id for\ndifferent physical servers"}
{"source":"gcp","filename":"compute_docs_nodes_sole_tenancy_accounting_faq","question":"in the event that my physical host is retired, can i trace the server_id lineage?","answer":"yes, each time a host is retired and you are provided a replacement host, the\nnew server_id is available in cloud audit logs"}
{"source":"gcp","filename":"compute_docs_nodes_sole_tenancy_accounting_faq","question":"how am i billed for a sole-tenant node?","answer":"you pay for the entire sole-tenant node on a per-second basis, regardless of how\nmany vms are running on the node"}
{"source":"gcp","filename":"compute_docs_nodes_sole_tenancy_accounting_faq","question":"can i pay for a commitment of longer than one year?","answer":"you can purchase sole-tenant nodes with a 1- or 3-year committed use\ndiscount, or you\ncan pay for them as you use them"}
{"source":"gcp","filename":"compute_docs_images_premium_sles_faq","question":"what is sles on compute engine?","answer":"suse linux enterprise server (sles) on compute engine are any sles images that\nare  optimized to run on google cloud"}
{"source":"gcp","filename":"compute_docs_images_premium_sles_faq","question":"what versions of sles are available on compute engine?","answer":"for a full list of the suse linux enterprise server (sles) versions that are\navailable on google  compute engine, see\noperating system details"}
{"source":"gcp","filename":"compute_docs_images_premium_sles_faq","question":"is sles for sap applications with high availability (ha) available on compute engine?","answer":"yes, sles for sap application with ha is available on compute engine"}
{"source":"gcp","filename":"compute_docs_images_premium_sles_faq","question":"what's the difference between sles and sles for sap applications?","answer":"suse linux enterprise server (sles) \nis a highly scalable, secure and enterprise class performant enterprise\noperating system for general linux workloads"}
{"source":"gcp","filename":"compute_docs_images_premium_sles_faq","question":"how are the public sles images made available on compute engine?","answer":"suse, in partnership with google, builds and maintains the sles images that\nare available on compute engine"}
{"source":"gcp","filename":"compute_docs_images_premium_sles_faq","question":"are there any differences between sles on google cloud and other versions that i run in my datacenter?","answer":"fundamentally, no, suse maintains the versions of sles and sles for sap\napplications that are available on compute engine, and the base os is identical\nto the version of sles available for installations on physical hardware"}
{"source":"gcp","filename":"compute_docs_images_premium_sles_faq","question":"what is the suse byos (bring your own subscription) program?","answer":"use the suse byos program to bring eligible suse product subscriptions to\ngoogle cloud"}
{"source":"gcp","filename":"compute_docs_images_premium_sles_faq","question":"are there any additional cost optimizations available for running suse on compute engine?","answer":"in addition to the pay-as-you-go (payg) license model that allows you to pay for\nonly what you  use, your infrastructure costs can be further reduced by taking\nadvantage of\ncommitted use discounts"}
{"source":"gcp","filename":"compute_docs_images_premium_sles_faq","question":"do your prices include tax?","answer":"no, the prices listed are exclusive of applicable taxes and duties, including\napplicable vat, and  applicable sales tax"}
{"source":"gcp","filename":"compute_docs_images_premium_sles_faq","question":"can i create sles vms in my free google cloud trial account?","answer":"yes, you can create sles vms in your free trial account"}
{"source":"gcp","filename":"compute_docs_images_premium_sles_faq","question":"how is support offered for pay-as-you-go (payg) sles licenses on compute engine?","answer":"when you are running payg suse images on  compute engine, access to google cloud\nsupport is included in the contract"}
{"source":"gcp","filename":"compute_docs_images_premium_sles_faq","question":"how is support offered for bring your own subscription (byos) licenses on compute engine?","answer":"if you bring your own suse subscription to google cloud, you will receive\nsupport directly from  suse"}
{"source":"gcp","filename":"compute_docs_images_premium_sles_faq","question":"how can i be notified when security updates are available for sles?","answer":"to be notified when security updates are made available by suse, subscribe to\nsuse  security announcements"}
{"source":"gcp","filename":"compute_docs_images_premium_sles_faq","question":"are there any restrictions on the machine types supported for suse on compute engine?","answer":"sles offerings are supported for all machine types in all regions"}
{"source":"gcp","filename":"compute_docs_images_premium_sles_faq","question":"what are the sap certified machine types on compute engine?","answer":"sap and google cloud certify both major and minor releases of sles on the\nmachine types that  are available on compute engine"}
{"source":"gcp","filename":"compute_docs_images_premium_sles_faq","question":"does suse provide long term\/extended service pack overlay support for sles versions post the end date of general support phase?","answer":"yes, suse  provides long term service pack support (ltss) and extended service\npack overlay support (espos) for products that have reached their end of\ngeneral support date"}
{"source":"gcp","filename":"compute_docs_images_premium_sles_faq","question":"how does pay-as-you-go (payg) licenses work for sles on compute engine?","answer":"with payg, you pay for only what you use"}
{"source":"gcp","filename":"compute_docs_images_premium_sles_faq","question":"how does the bring your own subscription (byos) license model work for sles on compute engine?","answer":"you will need an active suse \nsubscription to specify your own license on sles images on compute engine"}
{"source":"gcp","filename":"compute_docs_images_premium_sles_faq","question":"can i switch from payg to byos or byos to payg?","answer":"currently, switching between these two licensing options is not supported on\ncompute engine"}
{"source":"gcp","filename":"compute_docs_images_premium_sles_faq","question":"can i use google provided sles images and specify a byos license?","answer":"yes, you can use byos with google cloud provided sles images"}
{"source":"gcp","filename":"compute_docs_images_premium_sles_faq","question":"can i use my own sles images on compute engine?","answer":"yes, you can add vm instances, custom images, or disks that are available in an\nexisting  environment (such as on-premise or on other cloud providers) to\ncompute engine"}
{"source":"gcp","filename":"compute_docs_images_premium_sles_faq","question":"how do i get started with a sles vm on compute engine?","answer":"to create a new suse sles vm instance on compute engine, see the\nquickstart guide guide"}
{"source":"gcp","filename":"compute_docs_images_premium_sles_faq","question":"i plan to migrate sles vms from aws or azure to compute engine. what  is the recommended toolset or method to do so?","answer":"you can add vm instances, custom images, or disks that are available in an\nexisting  environment, such as on-premise or on other cloud providers, to\ncompute engine"}
{"source":"gcp","filename":"docs_ios_troubleshooting_faq","question":"what versions of xcode does firebase support?","answer":"firebase supports up to two major versions of xcode, not including versions\n    of xcode that apple no longer supports"}
{"source":"gcp","filename":"compute_docs_images_premium_rhel_faq","question":"what is red hat enterprise linux on compute engine?","answer":"red hat enterprise linux on compute engine are any rhel images that are\noptimized to run on compute engine"}
{"source":"gcp","filename":"compute_docs_images_premium_rhel_faq","question":"what versions of rhel are available on compute engine?","answer":"for a full list of the rhel versions that are available on compute engine,\nsee rhel operating system details"}
{"source":"gcp","filename":"compute_docs_images_premium_rhel_faq","question":"is rhel for sap with high availability and update services available on compute engine?","answer":"yes, rhel for sap with ha and update services is available on compute engine"}
{"source":"gcp","filename":"compute_docs_images_premium_rhel_faq","question":"how are the public rhel images made available on compute engine?","answer":"the rhel images that are available on compute engine are built by google\nin partnership with red hat"}
{"source":"gcp","filename":"compute_docs_images_premium_rhel_faq","question":"what is the red hat cloud access program?","answer":"the red hat cloud access program allows you to use eligible red hat product\nsubscriptions on compute engine"}
{"source":"gcp","filename":"compute_docs_images_premium_rhel_faq","question":"are there any further cost optimizations available for running rhel on compute engine?","answer":"in addition to the pay-as-you-go (payg) license model that allows you to pay for\nonly what you use, your infrastructure costs can be further reduced by taking\nadvantage of committed use discounts"}
{"source":"gcp","filename":"compute_docs_images_premium_rhel_faq","question":"can i create rhel vms in my free google cloud trial account?","answer":"yes, you can create rhel vms in compute engine on your free trial account"}
{"source":"gcp","filename":"compute_docs_images_premium_rhel_faq","question":"how is support offered for pay-as-you-go (payg) rhel licenses on compute engine?","answer":"when you are running payg rhel images on compute engine, access to\ngoogle cloud support is included in the contract"}
{"source":"gcp","filename":"compute_docs_images_premium_rhel_faq","question":"how can i be notified when updates are available for rhel?","answer":"to be notified when updates are made available by red hat, subscribe to\nred hat security announcements"}
{"source":"gcp","filename":"compute_docs_images_premium_rhel_faq","question":"are there any restrictions on the machine types supported for rhel on compute engine?","answer":"rhel is supported by all machine types in all regions"}
{"source":"gcp","filename":"compute_docs_images_premium_rhel_faq","question":"does google cloud provide extended lifecycle support for rhel versions post the end of maintenance phase?","answer":"yes, google does provide extended lifecycle support (els) for end-of-maintenance\nrhel versions"}
{"source":"gcp","filename":"compute_docs_images_premium_rhel_faq","question":"how does pay-as-you-go (payg) licenses work for rhel on compute engine?","answer":"you pay for only what you use"}
{"source":"gcp","filename":"compute_docs_images_premium_rhel_faq","question":"how does the bring your own subscription (byos) license model work for rhel on compute engine?","answer":"you will need an active\nred hat cloud access \nsubscription to specify your own license on rhel images in compute engine"}
{"source":"gcp","filename":"compute_docs_images_premium_rhel_faq","question":"can i use google provided rhel images and specify a byos license?","answer":"yes, you can use byos with google provided rhel images"}
{"source":"gcp","filename":"compute_docs_images_premium_rhel_faq","question":"can i use my own rhel images on compute engine?","answer":"yes, you can add vm instances, custom images, or disks that are available in\nan existing environment (such as on-premise or on other cloud providers) to\ncompute engine"}
{"source":"gcp","filename":"compute_docs_images_premium_rhel_faq","question":"how do i get started with a rhel vm on compute engine?","answer":"to create a new rhel vm instance on google compute engine, see the\nquickstart using a linux vm guide"}
{"source":"gcp","filename":"compute_docs_images_premium_rhel_faq","question":"i plan to migrate rhel instances from aws or azure to compute engine. what is the recommended toolset or method to do so?","answer":"you can add vm instances, custom images, or disks that are available in an\nexisting environment, such as on-premise or on other cloud providers, to\ncompute engine"}
{"source":"gcp","filename":"datastream_docs_faq","question":"what's datastream?","answer":"datastream is a serverless and easy-to-use change data capture (cdc) and replication service that allows you to synchronize data streams across heterogeneous databases and applications reliably and with minimal latency"}
{"source":"gcp","filename":"datastream_docs_faq","question":"what's cdc?","answer":"cdc is an approach to data integration that allows you to integrate and analyze data faster, using fewer system resources"}
{"source":"gcp","filename":"datastream_docs_faq","question":"what's backfill?","answer":"in addition to ongoing changes, datastream also uses backfill to pull all existing data from a source, and then stream the data into a destination"}
{"source":"gcp","filename":"datastream_docs_faq","question":"what's a change stream?","answer":"a change stream is a sequence of events that datastream emits to a destination such as cloud storage for downstream consumption"}
{"source":"gcp","filename":"datastream_docs_faq","question":"what's a materialized view?","answer":"a materialized view is a 1-to-1, up-to-date representation of a source table in a destination"}
{"source":"gcp","filename":"datastream_docs_faq","question":"does datastream require an agent on the source?","answer":"you don't have to install an agent on the source"}
{"source":"gcp","filename":"datastream_docs_faq","question":"what about the performance impact of datastream's usage on a production database?","answer":"cdc is a highly efficient mechanism for limiting the impact on the source when new data is loaded into destination data stores and data warehouses"}
{"source":"gcp","filename":"datastream_docs_faq","question":"can you copy the log files from the source to google cloud?","answer":"no, datastream queries the logs directly on the database server, and only changes to the specified tables are written to the destination"}
{"source":"gcp","filename":"datastream_docs_faq","question":"can datastream also transfer historical data?","answer":"yes, by default, datastream gets all historical data from the database tables of your source that you specify, in parallel to the cdc stream"}
{"source":"gcp","filename":"datastream_docs_faq","question":"what's the maximum row size that datastream supports?","answer":"datastream is currently limited to rows no larger than 3 mb"}
{"source":"gcp","filename":"datastream_docs_faq","question":"does datastream guarantee ordering?","answer":"datastream doesn't guarantee ordering"}
{"source":"gcp","filename":"datastream_docs_faq","question":"does datastream guarantee exactly-once delivery?","answer":"no, datastream is at-least-once delivery"}
{"source":"gcp","filename":"datastream_docs_faq","question":"how does datastream handle schema changes to a source?","answer":"datastream fetches the schema from the source periodically"}
{"source":"gcp","filename":"datastream_docs_faq","question":"can datastream stream specific tables and columns from a source?","answer":"yes, with datastream, you can specify include and exclude lists for tables and schemas, to stream only the data that you want from a source to a destination"}
{"source":"gcp","filename":"datastream_docs_faq","question":"how do you move a stream to another project or region?","answer":"create a stream in a new region or project with the same configuration as the existing stream, but don't select the backfill historical data check box"}
{"source":"gcp","filename":"datastream_docs_faq","question":"how does datastream handle uncommitted transactions in the database log files?","answer":"when database log files contain uncommitted transactions, if any transactions are rolled back, then the database reflects this in the log files as \"reverse\" data manipulation language (dml) operations"}
{"source":"gcp","filename":"datastream_docs_faq","question":"what's datastream's regional availability?","answer":"to view a listing of the regions where datastream is available, see ip allowlists and regions"}
{"source":"gcp","filename":"datastream_docs_faq","question":"how does datastream get data out of mysql?","answer":"datastream uses mysql's binary log to extract the change events from mysql"}
{"source":"gcp","filename":"datastream_docs_faq","question":"does datastream support cloud sql for mysql read replica instances?","answer":"yes, datastream supports read replica instances for cloud sql for mysql versions 5"}
{"source":"gcp","filename":"datastream_docs_faq","question":"how does datastream get data out of oracle?","answer":"datastream uses oracle logminer to extract the data from oracle's redo logs"}
{"source":"gcp","filename":"datastream_docs_faq","question":"does datastream require a goldengate license from oracle?","answer":"no, datastream uses oracle logminer to read the data from the database's redo logs"}
{"source":"gcp","filename":"datastream_docs_faq","question":"what happens when oracle logminer isn't supported anymore?","answer":"oracle will be supported for future releases"}
{"source":"gcp","filename":"datastream_docs_faq","question":"does datastream support encryption of data in-transit from oracle databases?","answer":"datastream supports encryption of data in-transit based on oracle net services"}
{"source":"gcp","filename":"datastream_docs_faq","question":"does datastream support oracle multi-tenant architecture, specifically container databases (cdbs) and pluggable databases (pdbs)?","answer":"datastream doesn't support cdbs and pdbs currently, but this is on our roadmap"}
{"source":"gcp","filename":"datastream_docs_faq","question":"what are some common use cases for using datastream?","answer":"datastream is a cdc and replication service, which means it's flexible across various use cases that can benefit from access to continuously streaming change data"}
{"source":"gcp","filename":"datastream_docs_faq","question":"how does datastream integrate with google cloud data services?","answer":"datastream complements and enhances the google cloud data suite by providing cdc data replication from sources to various google cloud services"}
{"source":"gcp","filename":"datastream_docs_faq","question":"what source versions does datastream support?","answer":"for mysql, datastream supports versions 5"}
{"source":"gcp","filename":"datastream_docs_faq","question":"how does datastream extract data from the sources?","answer":"for mysql, datastream processes the mysql binary log to extract  change events"}
{"source":"gcp","filename":"datastream_docs_faq","question":"can you copy log files directly from a source to google cloud?","answer":"datastream doesn't copy the entirety of the log files, but queries the log files directly from the database server, and only replicates changes from the specified tables to the destination"}
{"source":"gcp","filename":"datastream_docs_faq","question":"for oracle sources, does datastream require a goldengate license?","answer":"datastream doesn't require a goldengate license because it uses oracle logminer to read the data from the database's redo logs"}
{"source":"gcp","filename":"datastream_docs_faq","question":"what are the limitations on the data that datastream can process?","answer":"there are general limitations, limitations for mysql sources, and limitations for oracle sources"}
{"source":"gcp","filename":"datastream_docs_faq","question":"which data is included in every event that's generated by datastream?","answer":"each generated event (for inserts, updates, and deletes) includes the entire row of data from the source, with the data type and value of each column"}
{"source":"gcp","filename":"datastream_docs_faq","question":"how does datastream represent data types from the source for use in downstream processing?","answer":"datastream makes downstream processing of data across data sources easy and straightforward by normalizing data types across all sources"}
{"source":"gcp","filename":"datastream_docs_faq","question":"how does datastream handle structure (schema) changes in the source?","answer":"datastream tracks changes to the source data structure continuously"}
{"source":"gcp","filename":"datastream_docs_faq","question":"is datastream a secure service for sensitive data?","answer":"datastream supports multiple secure, private connectivity configurations to protect data in transit as it's streamed from a source to a destination"}
{"source":"gcp","filename":"datastream_docs_faq","question":"how can i limit datastream's processing of sensitive data?","answer":"datastream allows you to specify which specific data elements (schemas, tables, and columns) of your source you want to stream into a destination, and which elements you want to exclude from being streamed"}
{"source":"gcp","filename":"datastream_docs_faq","question":"how does datastream keep database credentials secure?","answer":"all user metadata (including the username and password used to access the data sources) is encrypted in transit and at rest"}
{"source":"gcp","filename":"datastream_docs_faq","question":"how are files created in cloud storage?","answer":"datastream creates a folder for each table"}
{"source":"gcp","filename":"datastream_docs_faq","question":"if data in cloud storage isn't ordered, then how can the events be reordered before loading them into the destination?","answer":"each event contains several metadata fields that uniquely identify the row in the oracle redo log"}
{"source":"gcp","filename":"datastream_docs_faq","question":"if multiple files are created for the same timestamp, then in which order should they be processed?","answer":"because ordering within and across files isn't guaranteed, the best way to determine the order to process the files is to get all events from all files for the specific timestamp, and then apply ordering using the method mentioned above"}
{"source":"gcp","filename":"datastream_docs_faq","question":"how are primary key updates handled? is there before and after information in the event?","answer":"the row_id metadata field uniquely identifies the row that's changing"}
{"source":"gcp","filename":"datastream_docs_faq","question":"how do i know when all of my historical data has been copied to the destination cloud storage bucket?","answer":"datastream provides information about its current status in the log files"}
{"source":"gcp","filename":"datastream_docs_faq","question":"how is datastream priced?","answer":"datastream is priced based on the volume (gb) of data that's streamed from your source into a destination"}
{"source":"gcp","filename":"datastream_docs_faq","question":"how do you calculate the size of the data?","answer":"billing is calculated based on the raw (uncompressed) data size that's streamed from the source to the destination"}
{"source":"gcp","filename":"datastream_docs_faq","question":"if you use datastream with dataflow or cloud data fusion, then what do you pay for?","answer":"each service is priced and charged for separately"}
{"source":"gcp","filename":"datastream_docs_faq","question":"what if i have additional questions or issues with using datastream?","answer":"google's support team can provide support if you're having issues with using datastream"}
{"source":"gcp","filename":"iap_docs_faq","question":"why is there a # at the end of my url after signing in to my app?","answer":"in some browsers and under certain conditions, a # may be appended to the\nurl after authentication"}
{"source":"gcp","filename":"iap_docs_faq","question":"why are my requests failing and returning a 405 method not allowed status code?","answer":"this can be caused by not attaching cookies to your requests"}
{"source":"gcp","filename":"iap_docs_faq","question":"why am i receiving an http 401 unauthorized status code instead of an http 302 redirect?","answer":"iap responds with a 302 redirect status code when a client\nis configured to handle redirects"}
{"source":"gcp","filename":"iap_docs_faq","question":"why are post requests not triggering redirects?","answer":"to trigger redirects, ensure that calls to iap aren't\npost requests"}
{"source":"gcp","filename":"iap_docs_faq","question":"can i use iap if i have disabled the api?","answer":"yes, access to resources secured with iap works with the api\ndisabled, but you won't be able to make changes to iam\npermissions"}
{"source":"gcp","filename":"iap_docs_faq","question":"how can i restrict users with the owner role from using iap for tcp?","answer":"first, avoid using the owner (roles\/owner) role as much as possible"}
{"source":"gcp","filename":"iap_docs_faq","question":"what domain does iap for tcp use?","answer":"iap tcp tunnels data through the domain tunnel"}
{"source":"gcp","filename":"translate_data_usage","question":"does google look at or use the text i send to the cloud translation api?","answer":"google does not use any of your content for any purpose except to provide\n    you with the cloud translation api service"}
{"source":"gcp","filename":"translate_data_usage","question":"will google share the text i send to the cloud translation api?","answer":"we will not make the content of the text that you send available to the\n    public"}
{"source":"gcp","filename":"translate_data_usage","question":"will the text i send to the cloud translation api, the results, or other\n    information about the request itself, be stored on google servers? if so,\n    how long and where is the information kept?","answer":"when you send text to cloud translation api, text is held briefly in-memory in\n    order to perform the translation and return the results to you"}
{"source":"gcp","filename":"translate_data_usage","question":"how does google protect and ensure the security of the data i send to\n    cloud translation api?","answer":"please refer to the google cloud security\n    page, and the data processing and security terms,\n    which describe the security measures in place for google's cloud\n    services"}
{"source":"gcp","filename":"translate_data_usage","question":"does google use my data for improving google translation support?","answer":"google does not use the content you send to train and improve\n  our google translation features"}
{"source":"gcp","filename":"translate_data_usage","question":"does google claim ownership of the content i send in the request to the\n    cloud translation api?","answer":"google does not claim any ownership in any of the content (including\n    text and labels) that you transmit to the cloud translation api"}
{"source":"gcp","filename":"translate_data_usage","question":"can i resell the cloud translation api?","answer":"no, you are not permitted to resell the cloud translation api\n    service"}
{"source":"gcp","filename":"translate_data_usage","question":"how does cloud translation api relate to gdpr compliance?","answer":"please refer to the google\n    cloud and the general data protection regulation\n    page which describes google cloud commitments to the gdpr"}
{"source":"gcp","filename":"translate_data_usage","question":"how are glossaries stored?","answer":"glossaries are encrypted and stored securely on google cloud, are in\n    compliance with google cloud data processing and security terms,\n    and can be managed from your google cloud project"}
{"source":"gcp","filename":"translate_data_usage","question":"who can access my glossaries?","answer":"cloud translation provides fine-grained iam permissions, so\n    only principals with the proper permissions can access your glossaries"}
{"source":"gcp","filename":"data_fusion_docs_resources_faq","question":"how is cloud data fusion priced?","answer":"see the cloud data fusion pricing page"}
{"source":"gcp","filename":"data_fusion_docs_resources_faq","question":"what support is provided for cloud data fusion?","answer":"google provides official support for cloud data fusion based on your\nsupport level"}
{"source":"gcp","filename":"data_fusion_docs_resources_faq","question":"how does cloud data fusion handle data location?","answer":"you use cloud data fusion to build pipelines that move data from one\nlocation to another"}
{"source":"gcp","filename":"data_fusion_docs_resources_faq","question":"can i export pipelines from cdap into cloud data fusion?","answer":"yes, the pipelines that you created in cdap are fully compatible with\ncloud data fusion"}
{"source":"gcp","filename":"automl_docs_data_usage_faq","question":"does google look at or use the content i send to automl?","answer":"google does not use any of your content for any purpose except\n    to provide you with the automl service"}
{"source":"gcp","filename":"automl_docs_data_usage_faq","question":"will google share the content i send to automl?","answer":"we will not make the content that you send available to the\n    public, or share it with anyone else, except as necessary to provide the\n    automl service"}
{"source":"gcp","filename":"automl_docs_data_usage_faq","question":"will the content i send to automl, the results, or other\n    information about the request itself, be stored on google servers? if so,\n    how long and where is the information kept, and do i have access to it?","answer":"when you import training data to automl, google needs to store\n    that content in order to train a machine learning model"}
{"source":"gcp","filename":"automl_docs_data_usage_faq","question":"does google use my data for improving google products?","answer":"currently, google does not use the content you send to train and improve\n  our features"}
{"source":"gcp","filename":"automl_docs_data_usage_faq","question":"does google claim ownership of the content i send in the request to the\n    automl?","answer":"google does not claim any ownership in any of the content that you\n    transmit to automl"}
{"source":"gcp","filename":"automl_docs_data_usage_faq","question":"can i resell automl?","answer":"no, you are not permitted to resell the automl\n    service"}
{"source":"gcp","filename":"storage_docs_faq_hl_id","question":"where can i find pricing information?","answer":"read the pricing page for detailed information on pricing,\nincluding how cloud storage calculates bandwidth and storage usage"}
{"source":"gcp","filename":"storage_docs_faq_hl_id","question":"where can i find billing information?","answer":"read the billing questions page, which provides relevant links to the\ncloud billing documentation"}
{"source":"gcp","filename":"storage_docs_faq_hl_id","question":"what are my support options?","answer":"see the cloud storage getting support page for information about\nsupport options"}
{"source":"gcp","filename":"storage_docs_faq_hl_id","question":"does cloud storage offer a service level agreement (sla)?","answer":"yes, you are covered under the cloud storage service level agreement"}
{"source":"gcp","filename":"storage_docs_faq_hl_id","question":"how do i notify google of sla financial credit eligibility?","answer":"use the sla financial credit eligibility form"}
{"source":"gcp","filename":"storage_docs_faq_hl_id","question":"how do i give product feedback?","answer":"from the cloud storage documentation click \"send feedback\" near the top\nright of the page"}
{"source":"gcp","filename":"storage_docs_faq_hl_id","question":"when do i need to activate cloud storage and enable billing?","answer":"if you want to create buckets, store data, or control who can access your\ndata, you must activate cloud storage and enable billing"}
{"source":"gcp","filename":"storage_docs_faq_hl_id","question":"how do i sign up?","answer":"sign up for cloud storage by turning on the cloud storage service in the\ngoogle cloud console"}
{"source":"gcp","filename":"storage_docs_faq_hl_id","question":"do i need to activate cloud storage and turn on billing if i was granted access to someone else's bucket?","answer":"no, in this case another individual has already set up a google cloud project\nand either granted you access to the entire project or to one of their\nbuckets and the objects it contains"}
{"source":"gcp","filename":"storage_docs_faq_hl_id","question":"i am just trying to download or access some data that is freely available to the public. how can i do that?","answer":"simply follow the accessing public data guide, which offers several\nmethods for accessing freely available, public data that is stored in\ncloud storage"}
{"source":"gcp","filename":"storage_docs_faq_hl_id","question":"i'm developing a library or tool for cloud storage and i want to sell it on the internet. is this okay?","answer":"yes!"}
{"source":"gcp","filename":"storage_docs_faq_hl_id","question":"how durable is my data in cloud storage?","answer":"cloud storage is designed for 99"}
{"source":"gcp","filename":"storage_docs_faq_hl_id","question":"how can i maximize the availability of my data?","answer":"consider storing your data in a multi-regional or dual-regional\nbucket location if high availability is a top requirement"}
{"source":"gcp","filename":"storage_docs_faq_hl_id","question":"what other advantages does cloud storage provide for disaster recovery scenarios?","answer":"cloud storage always provides strongly consistent object listings from a\nsingle bucket, even for buckets with data replicated across multiple\nregions"}
{"source":"gcp","filename":"storage_docs_faq_hl_id","question":"how do i protect myself from accidental data deletion?","answer":"cloud storage offers several different ways for you to protect your\ndata from accidental deletion"}
{"source":"gcp","filename":"storage_docs_faq_hl_id","question":"can i delete a cloud storage object that i accidentally uploaded to a locked, retention-enabled bucket?","answer":"no, you can only delete such an object after it has fulfilled its retention\nperiod"}
{"source":"gcp","filename":"storage_docs_faq_hl_id","question":"i believe some content hosted on your service is inappropriate, how do i report it?","answer":"certain types of content are not allowed on this service; please refer to the\nterms of services and platform policies for details"}
{"source":"gcp","filename":"storage_docs_faq_hl_id","question":"what is the default bucket location if i do not specify a location constraint?","answer":"the default bucket location is within the us"}
{"source":"gcp","filename":"storage_docs_faq_hl_id","question":"can i move buckets from one location to another or change the project that the bucket is associated with?","answer":"changing a bucket's location or project is not intrinsically provided by\ncloud storage; a bucket remains in the location and project that you set\nduring bucket creation"}
{"source":"gcp","filename":"storage_docs_faq_hl_id","question":"how can i get a summary of space usage for a cloud storage bucket?","answer":"you can use cloud monitoring for daily monitoring of your bucket's byte\ncount, or you can use the gsutil du command to get the total bytes in\nyour bucket at a given moment"}
{"source":"gcp","filename":"storage_docs_faq_hl_id","question":"i created a bucket, but don't remember which project i created it in. how can i find it?","answer":"for most common cloud storage operations, you only need to specify the\nrelevant bucket's name, not the project associated with the bucket"}
{"source":"gcp","filename":"storage_docs_faq_hl_id","question":"can i use cloud storage to upload files to services in google workspace, such as google drive?","answer":"no, cloud storage is not integrated with google workspace"}
{"source":"gcp","filename":"storage_docs_faq_hl_id","question":"can i use cloud storage with my google workspace account or cloud identity domain?","answer":"yes, you can use cloud storage with either"}
{"source":"gcp","filename":"storage_docs_faq_hl_id","question":"does google offer other unstructured storage options?","answer":"yes, google offers several storage options for unstructured data, such as\ngoogle drive"}
{"source":"gcp","filename":"storage_docs_faq_hl_id","question":"can charges associated with accessing data be billed to the user who accesses the data?","answer":"yes, you can use the requester pays feature to require that requesters\ninclude a billing account project in their requests"}
{"source":"gcp","filename":"storage_docs_faq_hl_id","question":"does cloud storage provide any acceleration capabilities for uploads and downloads?","answer":"yes, cloud storage allows customers to use a global dns name for uploads\nand downloads"}
{"source":"gcp","filename":"storage_docs_faq_hl_id","question":"i want to let someone download an individual object. how do i do that?","answer":"there are several ways that you can share an individual object"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"what is dataproc?","answer":"dataproc is a fast, easy-to-use, low-cost and fully managed service\nthat lets you run the apache spark and apache hadoop ecosystem\non google cloud platform"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"how is dataproc different from traditional hadoop clusters?","answer":"dataproc is a managed spark\/hadoop service intended to make spark and\nhadoop easy, fast, and powerful"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"how can i use dataproc?","answer":"there are a number of ways you can use a dataproc cluster depending on\nyour needs and capabilities"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"how does dataproc work?","answer":"dataproc is a managed framework that runs on the google cloud platform and\nties together several popular tools for processing data, including apache hadoop,\nspark, hive, and pig"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"what type of jobs can i run?","answer":"dataproc provides out-of-the box and end-to-end support for many of the\nmost popular job types, including spark, spark sql, pyspark, mapreduce, hive,\nand pig jobs"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"what cluster manager does dataproc use with spark?","answer":"dataproc runs\nspark on yarn"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"how frequently are the components in dataproc updated?","answer":"dataproc is updated when major releases occur in underlying components\n(hadoop, spark, hive, pig)"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"is dataproc integrated with other google cloud platform products?","answer":"yes, dataproc has native and automatic integrations with compute engine, cloud storage, bigtable, bigquery,\nlogging, and cloud monitoring"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"can i run a persistent cluster?","answer":"once started, dataproc clusters continue to run until shut down"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"can i run more than one cluster at a time?","answer":"yes, you can run more than one dataproc cluster per project simultaneously"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"how can i create or destroy a cluster?","answer":"you can create and destroy clusters in several ways"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"can i apply customized settings when i create a cluster?","answer":"dataproc supports initialization actions that are executed when a cluster\nis created"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"how do i size a cluster for my needs?","answer":"cluster sizing decisions are influenced by several factors, including the type\nof work to be performed, cost constraints, speed requirements, and your resource\nquota"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"can i resize my cluster?","answer":"yes, you can easily resize your cluster, even during job processing"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"how can i submit jobs on my cluster?","answer":"there are several ways to submit jobs on a dataproc cluster"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"can i run more than one job at a time?","answer":"yes, you can run more than one job at a time on a dataproc cluster"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"can i cancel jobs on my cluster?","answer":"definitely, jobs can be canceled via the google cloud console\nweb interface or the command line"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"can i automate jobs on my cluster?","answer":"jobs can be automated to run on clusters through several mechanisms"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"what development languages are supported?","answer":"you can use languages supported by the spark\/hadoop ecosystem, including java,\nscala, python, and r"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"does dataproc have an api?","answer":"yes, dataproc has a set of restful apis that allow you to programmatically\ninteract with clusters and jobs"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"can i ssh into a cluster?","answer":"yes, you can ssh into every machine (master or worker node) within a cluster"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"can i access the spark\/hadoop web uis?","answer":"yes, the hadoop and spark uis (spark, hadoop, yarn uis) are accessible within a\ncluster"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"can i install or manage software on my cluster?","answer":"yes, as with a hadoop cluster or server, you can install and manage software on\na dataproc cluster"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"what is the default replication factor?","answer":"due to performance considerations as well as the high reliability of storage\nattached to dataproc clusters, the default replication factor is set at 2"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"what operating system (os) is used for dataproc?","answer":"dataproc is based on debian and ubuntu"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"where can i learn about hadoop streaming?","answer":"you can review the\napache project documentation"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"how do i install the gcloud dataproc command?","answer":"when you install the cloud sdk, the standard gcloud\ncommand-line tool is installed, including gcloud dataproc commands"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"how can i get data in and out of a cluster?","answer":"dataproc utilizes the hadoop distributed file system (hdfs) for storage"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"can i use cloud storage with dataproc?","answer":"yes, dataproc clusters automatically install the cloud storage\nconnector"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"can i get cloud storage connector support?","answer":"yes, when used with dataproc, the cloud storage connector\nis supported at the same level as dataproc (see\nget support)"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"how reliable is dataproc?","answer":"because dataproc is built on reliable and proven google cloud platform\ntechnologies, including compute engine, cloud storage, and\nmonitoring, it is designed for high availability and reliability"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"what happens to my data when a cluster is shut down?","answer":"any data in cloud storage persists after your cluster is shut down"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"what sort of logging and monitoring is available?","answer":"by default, dataproc clusters are integrated with monitoring\nand logging"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"how can i view logs from dataproc?","answer":"you can view logs from dataproc in several ways"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"how can clusters be monitored?","answer":"clusters can be easily monitored through monitoring or the cloud\ndataproc section of the google cloud console"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"how is my data secured?","answer":"google cloud platform employs a rich security model, which also applies to cloud\ndataproc"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"how can i control access to my dataproc cluster?","answer":"google cloud platform offers authentication mechanisms, which can be used with\ndataproc"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"how is dataproc billed?","answer":"dataproc is billed by the second, and is based on the size of a cluster\nand the length of time the cluster is operational"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"am i charged for other google cloud resources?","answer":"yes, running a dataproc cluster incurs charges for other google cloud\nresources used in the cluster, such as compute engine and cloud storage"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"is there a minimum or maximum time for billing?","answer":"google cloud charges are calculated by the second, not by the hour"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"who can create a dataproc cluster?","answer":"dataproc is generally available which means all google cloud platform\ncustomers can use it"}
{"source":"gcp","filename":"dataproc_docs_resources_faq","question":"in which regions is dataproc available?","answer":"dataproc is available across all regions and zones of the google cloud\nplatform"}
{"source":"gcp","filename":"translate_media_docs_data_usage","question":"does google look at or use the audio i send to media translation?","answer":"google does not use any of your content for any purpose except to provide\n    you with the media translation service"}
{"source":"gcp","filename":"translate_media_docs_data_usage","question":"will google share the text i send to media translation?","answer":"we will not make the content of the text that you send available to the\n    public, or share it with anyone else, except as necessary to provide the\n    media translation service"}
{"source":"gcp","filename":"translate_media_docs_data_usage","question":"will the audio data i send to media translation, the results, or other\n    information about the request itself, be stored on google servers? if so,\n    how long and where is the information kept?","answer":"when you send audio data to media translation, we must store the audio and\n    converted text for a short period of time in order to perform the translation and\n    return the results to you"}
{"source":"gcp","filename":"translate_media_docs_data_usage","question":"does google claim ownership of the content i send in the request to the\n    media translation?","answer":"google does not claim any ownership in any of the content (including audio\n    and text) that you transmit to media translation"}
{"source":"gcp","filename":"translate_media_docs_data_usage","question":"can i resell the media translation?","answer":"no, you are not permitted to resell the media translation\n    service"}
{"source":"gcp","filename":"architecture_anthos_security_blueprints_faq","question":"how do i use the blueprints?","answer":"the\nanthos security blueprints \nrepository on github has resources and artifacts that show you how to achieve a\nset of security postures when you create or migrate workloads that use\nanthos clusters"}
{"source":"gcp","filename":"architecture_anthos_security_blueprints_faq","question":"are the blueprints the only way to achieve security postures when using anthos?","answer":"no, there are many ways to interpret and implement controls to achieve the\nsecurity postures"}
{"source":"gcp","filename":"architecture_anthos_security_blueprints_faq","question":"does the anthos blueprint collection include best practices for anthos clusters on vmware?","answer":"yes, most of the blueprints are applicable to anthos clusters wherever they\nare deployed"}
{"source":"gcp","filename":"architecture_anthos_security_blueprints_faq","question":"can the blueprints help me meet my regulatory compliance requirements?","answer":"the blueprints address a range of security postures"}
{"source":"gcp","filename":"architecture_anthos_security_blueprints_faq","question":"what services are supported by the guidance in these blueprints?","answer":"for a full list of supported services, see the implementation guide and the\nreadme files in the anthos\nsecurity blueprint repository \non github"}
{"source":"gcp","filename":"architecture_anthos_security_blueprints_faq","question":"do you accept contributions to the anthos security blueprints repository on github?","answer":"yes, you can submit a\npull request \nor fork the repository"}
{"source":"gcp","filename":"tpu_docs_faq","question":"are there  built-in tensorflow ops that are not available on\ncloud tpu?","answer":"there are a few built-in tensorflow ops that are not currently available on the\ncloud tpu"}
{"source":"gcp","filename":"tpu_docs_faq","question":"can i train a reinforcement learning (rl) model with a cloud tpu?","answer":"reinforcement learning covers a wide array of techniques, some of which\ncurrently are not compatible with the software abstractions for tpus"}
{"source":"gcp","filename":"tpu_docs_faq","question":"can i use embeddings with a cloud tpu?","answer":"yes, you can use the tpuembedding layer\nto support embeddings in keras models"}
{"source":"gcp","filename":"tpu_docs_faq","question":"can i use variable-length sequences with cloud tpu?","answer":"there are several methods for representing variable-length sequences in\ntensorflow, including padding, tf"}
{"source":"gcp","filename":"tpu_docs_faq","question":"can i train a recurrent neural network (rnn) on cloud tpu?","answer":"yes, to train a rnn with tensorflow, use\nkeras rnn layers"}
{"source":"gcp","filename":"tpu_docs_faq","question":"can i train a generative adversarial network (gan) with cloud tpu?","answer":"training gans typically requires frequently alternating between training the\ngenerator and training the discriminator"}
{"source":"gcp","filename":"tpu_docs_faq","question":"can i train a multi-task learning model with cloud tpu?","answer":"if the tasks can be represented as one large graph with an aggregate loss\nfunction, then no special support is needed for multi-task learning"}
{"source":"gcp","filename":"tpu_docs_faq","question":"does cloud tpu support tensorflow eager mode?","answer":"in tensorflow, users can use a @tf"}
{"source":"gcp","filename":"tpu_docs_faq","question":"does cloud tpu support model parallelism?","answer":"model parallelism (or executing non-identical programs on the multiple cores\nwithin a single cloud tpu device) is not currently supported"}
{"source":"gcp","filename":"tpu_docs_faq","question":"my training requirements are too complex or specialized for the\nkeras compile\/fit api, is there a lower-level api that i can use?","answer":"if you need lower-level control when using tensorflow, you can\nuse custom training loops"}
{"source":"gcp","filename":"spanner_docs_partners_drivers","question":"are indexes supported by this driver?","answer":"indexes are supported in select queries"}
{"source":"gcp","filename":"certificate_authority_service_docs_faqs","question":"what is certificate authority service?","answer":"certificate authority service is a highly available, scalable google cloud service that enables customers to simplify, automate, and customize the deployment, management, and security of private certificate authorities (cas) while staying in control of their private keys"}
{"source":"gcp","filename":"certificate_authority_service_docs_faqs","question":"what are the common use cases for certificate authority service?","answer":"given below are some common use cases for ca service"}
{"source":"gcp","filename":"certificate_authority_service_docs_faqs","question":"which compliance standards does ca service support?","answer":"ca service meets iso 27001, 27017, 27018, soc1, soc2, soc3, bsi c5, and pci compliance standards"}
{"source":"gcp","filename":"certificate_authority_service_docs_faqs","question":"which locations can we create ca service resources in?","answer":"ca service resources can be created in one of many locations"}
{"source":"gcp","filename":"certificate_authority_service_docs_faqs","question":"does ca service support a global pki under a single root?","answer":"yes, provided the root ca lives in a single region"}
{"source":"gcp","filename":"certificate_authority_service_docs_faqs","question":"are labels supported for cas?","answer":"yes, you can associate labels to ca pools and cas during create and update operations"}
{"source":"gcp","filename":"certificate_authority_service_docs_faqs","question":"is it possible to use cloud monitoring to track certificate creation and ca expiration? is it possible to generate pub\/sub events for them?","answer":"yes, you can monitor all of these events"}
{"source":"gcp","filename":"certificate_authority_service_docs_faqs","question":"how long are unactivated cas retained?","answer":"subordinate cas are created in the awaiting_user_activation state, and they are set to the staged state after activation"}
{"source":"gcp","filename":"certificate_authority_service_docs_faqs","question":"what access controls does ca service support for certificate issuance?","answer":"ca service supports setting iam policies on a ca pool to control who can issue certificates"}
{"source":"gcp","filename":"certificate_authority_service_docs_faqs","question":"does ca service support multi-region cloud kms keys?","answer":"no, ca service does not support multi-region cloud kms keys"}
{"source":"gcp","filename":"certificate_authority_service_docs_faqs","question":"will ca service ever throttle my requests? what is the target qps for ca service?","answer":"yes, there exists a throttling mechanism for ca service"}
{"source":"gcp","filename":"certificate_authority_service_docs_faqs","question":"does ca service support vpc service controls?","answer":"yes, ca service supports vpc service controls"}
{"source":"gcp","filename":"certificate_authority_service_docs_faqs","question":"how are pem encoded public keys supposed to be used with rest apis?","answer":"pem encoded public keys can only be used with rest apis after they have been base64 encoded"}
{"source":"gcp","filename":"certificate_authority_service_docs_faqs","question":"can preview stage apis still be used after ca service announces general availability (ga)?","answer":"yes, preview apis can still be used for a short period after ca service announces ga"}
{"source":"gcp","filename":"certificate_authority_service_docs_faqs","question":"how can resources created during the preview period be accessed after ca service announces general availability (ga)?","answer":"you cannot view or manage resources created during the preview period using the google cloud console"}
{"source":"gcp","filename":"istio_docs_istio_on_gke_migrate_faq","question":"why am i being migrated from istio on gke to anthos service mesh?","answer":"istio on google kubernetes engine is a beta feature that deploys google-managed istio on a\ngoogle kubernetes engine (gke) cluster"}
{"source":"gcp","filename":"istio_docs_istio_on_gke_migrate_faq","question":"are there any features or configurations that are not supported in the latest version of anthos service mesh?","answer":"the script checks all istio configurations and migrates them to the latest\nanthos service mesh version"}
{"source":"gcp","filename":"istio_docs_istio_on_gke_migrate_faq","question":"what happens if i don't migrate to anthos service mesh?","answer":"your istio components continue to work, but google no longer manages your istio\ninstallation"}
{"source":"gcp","filename":"anthos_multicluster_management_connect_faq","question":"which versions of kubernetes and types of clusters can be connected?","answer":"connect is designed to work with\ngke versions"}
{"source":"gcp","filename":"anthos_multicluster_management_connect_faq","question":"what happens if a cluster's agent gets disconnected?","answer":"if the network connection for a cluster agent is disrupted, the agent will periodically attempt to reconnect"}
{"source":"gcp","filename":"anthos_multicluster_management_connect_faq","question":"how many clusters can i connect?","answer":"see quotas and limits"}
{"source":"gcp","filename":"anthos_multicluster_management_connect_faq","question":"does connect support vpc-sc?","answer":"yes, connect works with vpc service controls (vpc-sc), and it is considered a supported product"}
{"source":"gcp","filename":"anthos_multicluster_management_connect_faq","question":"can i install kubernetes applications from the marketplace?","answer":"if you want to deploy a kubernetes application to non-standard cluster\nconfigurations, such as a anthos clusters on vmware cluster, you must complete some\nadditional tasks"}
{"source":"gcp","filename":"bigquery_docs_materialized_views_faq","question":"when should i use scheduled queries versus materialized views?","answer":"scheduled queries are a convenient way to run arbitrarily complex\ncalculations periodically"}
{"source":"gcp","filename":"bigquery_docs_materialized_views_faq","question":"how fast is a change in the base table reflected when querying the materialized view?","answer":"immediately, whether you stream into the base table, bulk load data into it, or\nrun a query that writes the results into the base table, the new table state is\nreflected immediately when you perform a query, even if the materialized view\nhasn't been refreshed yet"}
{"source":"gcp","filename":"bigquery_docs_materialized_views_faq","question":"how frequently is a materialized view refreshed?","answer":"each materialized view is automatically refreshed (recomputed) when the base\ntable changes, but not more often than a certain interval"}
{"source":"gcp","filename":"bigquery_docs_materialized_views_faq","question":"how can i tell if a query was rewritten by the optimizer to utilize a materialized view?","answer":"inspect the query plan"}
{"source":"gcp","filename":"bigquery_docs_materialized_views_faq","question":"how can i disable query rewrite for a particular query?","answer":"the bigquery query optimizer rewrites your query automatically\nin order to leverage a materialized view"}
{"source":"gcp","filename":"bigquery_docs_materialized_views_faq","question":"does a query trigger an automatic refresh of the materialized view?","answer":"no, a query doesn't automatically trigger a materialized view refresh"}
{"source":"gcp","filename":"bigquery_docs_materialized_views_faq","question":"why am i getting these errors?","answer":"the following lists details on common errors"}
{"source":"gcp","filename":"bigquery_docs_materialized_views_faq","question":"some queries over materialized views are slower than same queries over manually materialized tables. why is that?","answer":"in general, a query over a materialized view isn't always as performant as a\nquery\nover the equivalent materialized table"}
{"source":"gcp","filename":"asset_inventory_docs_faq","question":"is cloud asset inventory a global service?","answer":"yes, cloud asset api has no dependence on location"}
{"source":"gcp","filename":"asset_inventory_docs_faq","question":"why do i not have permission to use the cloud asset api?","answer":"an error is returned if you don't have permission to export assets\nor get the history on an organization, project, or folder"}
{"source":"gcp","filename":"asset_inventory_docs_faq","question":"why is the cloud asset api result stale?","answer":"data freshness in the cloud asset api is on a best-effort basis"}
{"source":"gcp","filename":"asset_inventory_docs_faq","question":"why do i see different ancestors for the same assets?","answer":"when calling the cloud asset api to get different metadata types, such as resource\nmetadata and iam policy metadata for the same asset, it is possible that the\nancestors field is inconsistent across content types"}
{"source":"gcp","filename":"asset_inventory_docs_faq","question":"why didn't i receive notifications for project deletions?","answer":"when you shut down a project, you have\n30 days\nto undo the operation"}
